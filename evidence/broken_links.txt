README.md: https://yippeee.tistory.com/79)
  - 재외국민신고 : 주민등록법상 재외국민이 아님(신고이름만 재외국민...)
  - 해외이주신고 : 주민등록상 재외국민

- 해외에 있어도 전산상의 오류로 의료보험 중지가 재개 되는 경우가 있는데, 이를 무시하면 뒤늦게 이의를 제기해도 소급된 비용 모두 내야 하는 경우가 있으니 주의가 필요. 
  - 2020년부터 의료비 먹튀자를 막기 위해 한국에 한 달이상 체류하거나 한 달 이내라고 하더라도 의료를 받고 나간 경우는 의료 보험이 재개됨.
- 한국내 주소지를 모두 정리한 경우 마지막 거주지의 주민센터 주소를 등록해야 함. 

## 기억하기 힘든 일본어

### 생선

광어 平目 ひらめ 히라메

가자미 鰈 かれい 카레이

참치 鮪 まぐろ 마구로🐟

임연수 ほっけ 홋케

농어 鱸 すずき 스즈키

방어 鰤 ぶり 부리

고등어 鯖 さば 사바

꽁치 秋刀魚 さんま 산마

학꽁치 さより 사요리

갈치 太刀魚 たちうお 타치우오

전갱이 鯵 あじ 아지

명태알  明太子 めんたいこ 멘타이코

연어 鮭 さけ 사케(술 お酒 おさけ 오사케)

연어알 いくら 이쿠라

청어알 かずのこ 카즈노코

열빙어 ししゃも 시샤모

문어 たこ 타코🐙

상어 鮫 さめ 사메🦈

전복 鮑 あわび 아와비

성게알 うに  우니

해삼 なまこ 나마코

멍게 ほや 호야

소라 さざえ 사자에

피조개 赤貝 あかがい 아카가이

가리비 帆立貝 ほたてがい 호타테가이

대합 蛤 はまぐり 하마구리

모시조개 あさり 아사리

미꾸라지 泥鰌 どじょう  도죠ㅡ

장어 鰻 うなぎ 우나기

갯장어 鱧 はも 하모

가다랭이 鰹 かつお 카츠오

복어 河豚 ふぐ 후구🐡

도미 たい 타이

대구 鱈 たら 타라

숭어 鯔 ぼら 보라

고래 鯨 くじら 쿠지라🐳

삼치 さわら 사와라

아귀 あんこう 안코ㅡ

아귀애(간) あん肝 あんきも 안키모

날치 飛魚 とびうお 토비우오

쥐취 かわはぎ 카와하기

정어리 いわし 이와시

오징어 いか 이카🦑

가오리류. 홍어 エイ 에이

새우 海老 えび 에비🦐

굴 かき 카키

게 かに 카니🦀

잡어 雑魚 じゃこ 쟈코 

あかむつ (のどくろ)ㅡ 아카무츠  또는 노도쿠로. 


## 비즈니스 지식 베이스(한글)

* [중소기업기술로드맵](http://smroadmap.smtech.go.kr/)
* [스마트공장1번가](https://1st.smart-factory.kr/pblancList.do)
* [범부처통합연구지원시스템-사업공고](https://www.iris.go.kr/contents/retrieveBsnsAncmBtinSituListView.do)

- [법인 설립 비용 계산](https://www.startbiz.go.kr/smba/cfs/pop/popFindCmpnyType.do?cmd=goCmpnyCal#null)

airtable.md: https://www.airtable.com/product


Chatbot.md: https://blog.est.ai/2019/11/task-oriented-dialog-systems-meet-bert/)

DeepSeekV3.md: https://github.com/deepseek-ai/DeepSeek-V3
    - 참고로 DeepSeek R1의 레포지토리에는 소스가 전혀 없고, V3를 베이스로 한다고 되어 있음.

## File Structure

주요 파일만 정리함.

### `/inference/model.py`

1. ModelArgs

    모델의 하이퍼파라미터를 정의하는 데이터 클래스.
    배치 크기, 시퀀스 길이, 차원 크기, MoE 설정 등의 다양한 설정값을 포함.

2. ParallelEmbedding

    대규모 모델에서 분산 학습을 위한 병렬 임베딩을 제공.

3. Linear

    저비트 연산 (FP8/BF16) 을 지원하는 선형 변환 연산.

4. ColumnParallelLinear & RowParallelLinear

    데이터 병렬 학습을 지원하는 선형 변환 연산.
    ColumnParallelLinear: 출력 차원을 병렬로 분할.
    RowParallelLinear: 입력 차원을 병렬로 분할.

5. RMSNorm

    LayerNorm 대신 Root Mean Square Normalization (RMSNorm) 사용.

6. MLA (Multi-Headed Attention Layer)

    표준 Transformer Attention을 개선한 MLA 구현.
    LoRA 기법을 활용하여 Query/Key/Value를 Low-rank 방식으로 압축.

7. MoE (Mixture-of-Experts)

    여러 개의 전문가 네트워크 (Expert Layer) 를 사용하여 성능을 최적화.
    Gate를 사용해 입력을 특정 전문가에게 라우팅.

8. Block

    Transformer의 기본 블록 (Attention + MoE/MLP).
    MLA + MoE(또는 MLP)를 조합하여 하나의 Transformer Layer를 구성.

9. Transformer
 
    전체 Transformer 모델을 정의.
    병렬 임베딩 + 여러 개의 Transformer 블록 + 최종 출력 레이어 포함.


### `/inference/kernel.py`
kernel.py 파일은 DeepSeek에서 사용되는 GPU 가속 커널을 구현한 코드입니다. 주요 내용은 다음과 같습니다:

1. 활성화(activation) quantization:

    act_quant_kernel와 act_quant 함수는 입력 텐서를 block 단위로 quantize합니다.
    각 블록에서 입력 텐서의 절대값 최댓값을 기반으로 scaling factor를 계산하고, 이를 사용해 텐서를 quantize하여 저장합니다. 

2. 가중치(weight) dequantization:

    weight_dequant_kernel와 weight_dequant 함수는 quantized된 가중치 텐서를 복원(dequantize)합니다.
    저장된 scaling factor를 사용해 원래의 값으로 복원하는 방식으로 구현되어 있습니다. 

3. FP8 GEMM 연산:

    fp8_gemm_kernel와 fp8_gemm 함수는 FP8 precision을 활용한 행렬 곱셈(GEMM)을 수행합니다.
    다양한 블록 크기 설정과 autotuning 기능을 사용해 최적의 성능을 도출하도록 구성되어 있습니다. 
    전체적으로, 이 코드는 트리톤(Triton) 라이브러리를 이용하여 GPU에서 효율적인 연산을 수행하도록 최적화된 커널들을 제공하며, DeepSeek의 연산 성능을 향상시키기 위한 핵심 요소들을 담고 있습니다.

### `/inference/generate.py`

generate.py 파일은 Transformer 모델을 사용하여 텍스트를 생성하는 기능을 제공하는 스크립트입니다. 주요 구성 요소는 다음과 같습니다:

1. 토큰 샘플링 함수(sample):

    logits를 temperature로 스케일링한 후 softmax를 적용하여 확률 분포를 만든 뒤, 노이즈를 추가하여 argmax로 다음 토큰을 선택합니다. 

2. 토큰 생성 함수(generate):

    주어진 프롬프트 토큰(prompt_tokens)을 기반으로 최대 max_new_tokens만큼 새로운 토큰을 순차적으로 생성합니다.
    입력 프롬프트를 먼저 tokens 텐서에 초기화한 뒤, 모델의 forward 함수를 이용하여 현재까지 생성된 토큰들을 입력으로 받아 logits를 계산합니다.
    온도(temperature) 값에 따라 샘플링 또는 argmax 선택을 하며, EOS 토큰이 등장하면 생성 과정을 종료합니다.
    최종적으로 프롬프트 이후의 생성된 토큰 리스트를 반환합니다. 

3. 메인 함수(main):

    모델 체크포인트와 설정 파일(config)을 읽어들여 Transformer 모델과 ModelArgs 객체를 생성합니다.
    분산 학습 환경을 지원하기 위해 world_size, rank, local_rank 등의 환경변수를 확인하고 NCCL 백엔드를 초기화합니다.
    safetensors 라이브러리를 이용해 모델 파라미터를 로드하며, Hugging Face의 AutoTokenizer를 사용하여 토크나이저를 초기화합니다.
    인터랙티브 모드와 배치 처리 모드를 모두 지원합니다.
    인터랙티브 모드에서는 사용자 입력을 받아 채팅 형식으로 텍스트를 생성하며, 
DeepSeekV3.md: https://github.com/LowyShin/KnowledgeBase/blob/master/dic/a/AI/PPO_DPO_KTO_GRPO_Comparison.md) 를 통한 [KL확산(Kullback-Leibler Divergence)](https://github.com/LowyShin/KnowledgeBase/blob/master/dic/a/AI/Kullback-Leibler.md) 처리에 대해 집중적으로 다루었으나 
이에 대한 내용이 없음. 

https://youtu.be/zFXmIoSQU5Q
![0201(1)](https://github.com/user-attachments/assets/67146c3b-32c4-4114-872a-5364fcc10267)


Root.md: https://kingroot.jp.malavida.com/android/
* KingoRoot Android
    * https://kingo-root.jp.malavida.com/android/
* Towelroot Android
    * https://towelroot.jp.malavida.com/android/

# Chrome browser Android emulator extension

* ARC Welder
    * https://chrome.google.com/webstore/detail/arc-welder/emfinbmielocnlhgmfkkmkngdoccbadn

## adb

If you use android studio, you may use adb shell no need rooting.

* adb shell dumpsys
    * [dumpsys command(jp)](https://moneyforward.com/engineers_blog/2014/11/17/android%E3%82%A2%E3%83%97%E3%83%AA%E9%96%8B%E7%99%BA%E8%80%85%E3%81%AA%E3%82%89%E7%9F%A5%E3%81%A3%E3%81%A6%E3%81%8A%E3%81%8F%E3%81%B9%E3%81%8Ddumpsys%E3%82%B3%E3%83%9E%E3%83%B3%E3%83%89/)

aws-rds-sqlserver.md: https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/SQLServer.Concepts.General.FeatureNonSupport.html


### 新機能 – Amazon RDS Custom for SQL Server が一般提供開始

https://aws.amazon.com/jp/blogs/news/new-amazon-rds-custom-for-sql-server-is-generally-available/

### RDS Customを使ってみた（SQL Server編）

https://qiita.com/kenichi_matsunaga/items/f7322b269e2e2c6812a6


aci.md: https://github.com/LowyShin/KnowledgeBase/blob/master/dic/c/containerservice.md)と呼ばれる隔離された環境を提供するサービスから出発したコンテナサービスはAzureの場合はACIにAWSの場合は Amazon ECSなどで提供されています。

コンテナはそもそも異なるアプリケーション環境を一つのOS上で稼働させサーバー台数を減らす目的で開発されていたのでその根本的な機能をしておいたら活用範囲が分かると思います。

![Linux Container Service](https://www.redhat.com/rhdc/managed-files/what-is-a-container.png)

最近コンテナサービスに合わせられるような環境も増えてきたのでnode14とnode16を同時に起動させたりすることがしやすくなっています。この環境を丸ごと動かすことで既存のOSを丸ごとコピーするより遥かに少ない容量と展開リソースで最近VMより使われるようになりました。

[コンテナサービス](https://github.com/LowyShin/KnowledgeBase/blob/master/dic/c/containerservice.md)が必要な場合はこの記事をそのまま見ながら似たようなサービスと比べるのをお勧めします。
しかし自動化の管理だけを目的としてコンテナサービスは道具の一部だと思った方は[バッチっサービス](azurebatch.md)をご覧ください。

Azure Container Apps の条件に当てはまらなかったりそれほど多くの機能を必要としないような、単体で動くシンプルなアプリケーションやバッチ処理に適したサービスです。
公式ドキュメントのAzure Container Instancesによると、「オンデマンドで Hyper-V 分離コンテナーの単一ポッドが提供されます。」と説明されています。また、スケーリング・負荷分散(ロードバランシング)・証明書などの機能も提供されません。
Azure Container Instances はあくまで単一ポッドなので、複数コンテナの連携・オートスケーリングなどが必要な場合は Azure Kubernetes Service を使用して、間接的に Azure Container Instances を利用する方法が最適です。Kubernetes API への直接アクセスが必要ない場合は Azure Container Apps の利用が良いでしょう。

- 他のコンテナと連携が必要ない
- スケーリング・負荷分散(ロードバランシング)・証明書の機能が必要ない
- 単一で動くシンプルなアプリケーション
- バッチ処理

<table style=
aci.md: https://github.com/LowyShin/KnowledgeBase/blob/master/dic/k/kuubernetes.md) の機能や Dapr・KEDA・envoy などのオープンソースのテクノロジーを活かして、Kubernetes スタイルのアプリやマイクロサービスを作るのに向いたサービスです。
サービス自体は Kubernetes 基盤で構築されていますが、Kubernetes API への直接アクセスは提供されません。
Kubernetes の機能を活かしたいが 1 から構築する必要性・知見がない中で、ある程度ベストプラクティスに沿いたい場合に向いています。
汎用的なので、迷ったらこれでいいかなと思います。

- 汎用コンテナ
- 多くののマイクロサービスと関わるアプリケーション
- イベント駆動型アプリケーションアーキテクチャ
- 実行時間の長いプロセス

### Azure App Service

App Serviceの設定中コンテナを利用してAppを構成できる設定があります。ACIの設定をしてDeployすることができてサーバーレスコンテナサービスになります。
Web アプリケーションのためのサービスです。
フルマネージドで Web サイトや Web API を構築したいときに向いています。
Windows/Linux ベースで .NET、.NET Core、Java、Ruby、Node.js、PHP、Python から環境を選択します。
バックグラウンドタスクも同じインスタンス内で追加料金なしで実行可能です。

- Web サイト
- Web API

### Azure Kubernetes Service

[Kubernetes](https://github.com/LowyShin/KnowledgeBase/blob/master/dic/k/kuubernetes.md)はDockerコンテナをGUIで管理がしやすくしたOpen Sourceツールです。管理がしやすいためAzureとAWSで取り入れサービスとして提供しています。
KubernetesはK8Sとも言われるですが、それはKと後8文字の英語とSがついてK8Sと呼んだりしてます。
Azure で Kubernetes をフル活用したい場合に最適なサービスです。
一番の特徴は Kubernetes API への直接アクセスがサポートされていることです。Kubernetes をフルマネージドで使用できます。
その代わり、クラスターの構成と運用はユーザーの制御と責任の範囲内となるため、クラウドサービスの利点が一部損なわれることには注意しましょう。

- フルマネージドで Kubernetes を使用したい
- Kubernetes API への直接アクセスが必要

### Azure Functions

サーバレスでサービスとしての関数(FaaS)です。イベント駆動型のアプリケーションを構築する場合に最適なサービスです。
スケーリングがしやすかったり、イベント駆動型アプリケーションを構築出来たりなど Azure Container Apps と似ていますが、一時的な関数実行を行う用途に最適化されています。
Azure Functions で作成したコードは基本的にコンテナイメージとしても使用できるので、後から環境を変えたい場合にも再利用しやすいというメリットもあります。
プランが 2 種類あり、デフォルトは従量課金プランでは、コールドスタート・最大実行時間が 10 分など制限があります。それに対して Premium プランは、設定で最大実行時間を無制限(60 分保証)に出来たり、常にウォーム状態に維持できるなど制限の緩和ができます。
どちらのプランも一時的な関数としての用途を基本としていますので、実行時間が比較的短い(最大 60 分未満)コンテナでイベント駆動型のアプリケーションを構築したい場合に良い選択肢です。

- サーバレスでコンテナアプリケーションを構築・運用
- 一時的に使用する関数
- 1 度の実行時間が短い(60 分未満)

### [Azure Red Hat OpenShift](https://github.com/LowyShin/KnowledgeBase/blob/master/dic/o/openshift.md)

OpenShift とは、Red Hat社が提供しているエンタープライズ対応のKubernetesコンテナプラットフォームで、Docker、Kubernetes、Dockerレジストリなどで構成されるCaaS(Container as a Service)基盤です。

Azure Red Hat OpenShift は Azure 上で OpenShift を使用したい場合に最適なサービスです。
ソースコード管理・ビルド・デプロイ・スケーリング・正常性の管理は、OpenShift の機能で自動的に行うことが出来ます。
レジストリ・ネットワーク・ストレージ・CI/CD は組み込みの機能を使うこともできますし、独自のものを使用することもできます。
元から OpenShift を使用して運用していたり、Kubernetes を本格的に運用する前提で、CI/CD ツールや長期のサポートなど、必要な他のツールや保守サービスも一通りほしい場合に便利です。

- システムを OpenShift で運用している
- Kubernetes を中心とした本格的な開発・運用
- CI/CD など他ツール一式を同時に導入したい
- Kubernetes を含めたツールの長期サポートがほしい

### Azure Spring Cloud

既存の Spring Boot のアプリケーションのコードを変更せずに Azure にデプロイしたい場合に最適なサービスです。
Spring bbot の実行環境を一から構築する必要がないのがメリットです。また、監視やブルー/グリーンデプロイなどもあります。
Spring Boot を使用する際は、コードを変更したりコンテナ用の構成管理ファイルを作成するわけではないので、コンテナを使用するような感覚はありませんが、内部的には専用の Kubernetes クラスターで管理されるようです。
参考 | Azure Spring Cloud では、アプリケーションがどのようにホストされますか?

- コードを変更せずに Spring boot アプリケーションをデプロイしたい
- コンテナ技術のノウハウなしにコンテナのメリットを享受したい

### [Azure Batch](https://azure.microsoft.com/ja-jp/products/batch)

Azure Batchとは、CPU・メモリなど多くのコンピュータリソースを必要とする大規模なバッチジョブを、Azure上で効率的に処理するための実行基盤です。Azure Batchを使用することで、下記のバッチジョブを効率的に実行することが可能になります。

- 大規模な並列処理を行うバッチジョブ
- 大量のマシンリソースを必要とする科学計算等の高負荷なバッチジョブ（ハイパフォーマンス・コンピューティング：HPC）

Azure Batchで管理された仮想マシン上で実行するようにスケジュールを設定し、バッチジョブの要件に合わせて仮想マシンを自動的にスケールさせながら大量のマシンリソースを要するバッチジョブを処理していきます。

## Reference

- [Azure Batch](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/azure/azurebatch.md)


azure-application-gateway.md: https://level69.net/archives/29838)

## Multi Domain on Single application gateway

### 환경

- 개발 서버 : dev.giip.net, devsvr.giip.net, devvm.giip.net (ws, was의 리스너용 및 실vm용 도메인 총 3 개를 준비해야 함.)
  - 4000포트에 ws기동. 프론트 웹 서버
  - 3000포트에 was기동. 백엔드 어플리케이션 서버
- 스테이징 서버 : stg.giip.net, stgvm.giip.net
  - 4000포트에 ws기동, prod환경의 was에 접속해서 최종 테스트
- 서비스 서버 : prod.giip.net, prodsvr.giip.net, prodvm.giip.net (ws, was의 리스너용 및 실vm용 도메인 총 3 개를 준비해야 함.)
  - 4000포트에 ws기동
  - 3000포트에 was기동

### 설정

1. Add backend pool
   - dev-be4000 : 개발 서버의 4000포트(WS)
     - FQDN : devvm.giip.net
   - dev-be3000 : 개발 서버의 3000포트(WAS)
     - FQDN : devvm.giip.net
   - stg-be4000 : 스테이징 서버의 4000포트(WS)
     - FQDN : stgvm.giip.net
   - prod-be4000 : 서비스용 4000포트(WS)
     - FQDN : prodvm.giip.net
   - prod-be3000 : 서비스용 3000포트(WAS)
     - FQDN : prodvm.giip.net

2. Add backedn configuration
   - ws-4000 : WS용 설정
     - Protocol : HTTP (내부적으로는 http통신으로 하기 때문)
     - Port : 4000
   - was-3000 : WAS용 설정
     - Protocol : HTTP (내부적으로는 http통신으로 하기 때문)
     - Port : 3000

3. Add listener
   - devws-lsnr443
     - Protocol : HTTPS
     - Port : 443
     - SSL : pkx파일 업로드
     - Listner 종류 : multi site
     - host 종류 : 복수 또는 와일드카드
       - dev.giip.net (이 도메인으로 접속하면 이 설정을 탐)
   - devwas-lsnr443
     - Protocol : HTTPS
     - Port : 443
     - SSL : pkx파일 업로드
     - Listner 종류 : multi site
     - host 종류 : 복수 또는 와일드카드
       - devsvr.giip.net(이 도메인으로 접속하면 이 설정을 탐)
   - stgws-lsnr443
   - prodws-lsnr443
   - prodwas-lsnr443

4. Add rule
   - devws-rr443
     - listener : devws-lsnr443
     - backend target : dev-be4000 (개발환경 도메인 연결)
     - backend configuration : ws-4000 (4000포트 설정 가져옴)
   - devwas-rr443
     - listener : devwas-lsnr443
     - backend target : dev-be3000 (개발환경 WAS 도메인 연결)
     - backend configuration : ws-3000 (3000포트 설정 가져옴)
   - stgws-rr443
   - prodws-rr443
   - prodwas-rr443

이런식으로 설정하면 하나의 agw로 여러 도메인 및 서버를 교통정리할 수 있음!

azurebatch.md: https://azure.microsoft.com/ja-jp/products/batch

### 特徴

- 何十台、何百台から何千台もの仮想マシンに拡張可能
- データのステージングおよびコンピューティング パイプラインの実行
- キュー内の作業の自動スケール機能
- クラウド対応のバッチ アプリケーションと HPC アプリケーション
- Linux または Windows を選択してジョブを実行可能
- 資本投資せずに使用分のみ従量課金


## Azure における統合と自動化の適切なサービスを選ぶ

### [Microsoft Power Automate](https://make.powerautomate.com/) (旧称 Microsoft Flow)

Power AutomateはITに詳しくない人がパソコン上の作業を自動化することに特化して開発されたものでWWF(Windows Workflow Foundation)から派生した商品と思われます。GUIが便利で業務フローを作成して簡単なコードだけ入れたらすぐ作業ができ、自動化までサポートしているので簡単に自動化ができます。
ITの人ならVisual StudioからWWFを追加して開発するのも良いですが、Power Automateの豊かなコンポネントを利用すると生産性の高さに魅了されると思います。
サーバーエンジニアの場合バッチファイルを作成してPower Automateで動かすことも可能なので幅広く使えるツールだと思います。

### [Azure Logic Apps](https://azure.microsoft.com/ja-jp/products/logic-apps/)

Azure Logic Apps は、コンテナー化されたランタイム上に構築された、主要なサービスとしての統合プラットフォーム (iPaaS) です。どこでも Logic Apps をデプロイして実行することができ、ビジネスクリティカルなワークフローをどこでも自動化しながら、スケールと移植性を向上させることができます。

基本的に企業から大量のバッチが必要な場合拡張がしやすく統合管理がしやすい特徴があるのでバッチが専門の仕事には向いていると思います。
しかし、バッチ処理が少ないまたは種類が少ない場合はPower AutomateまたはAzure Functionでもいいかと思います。

### [Azure Functions](https://azure.microsoft.com/ja-jp/products/functions/)

Azure Functions は、任意のプログラミング言語を使用してより効率的に開発するのに役立つ、イベント ドリブン型サーバーレス コンピューティング プラットフォームです。最高レベルのハードウェア抽象化を備えたコア ビジネス ロジックに焦点を当てます。複雑なオーケストレーションの課題を簡素化し、ローカルでビルドおよびデバッグし、クラウドで大規模にデプロイし、トリガーとバインドを使用して関数を Azure サービスに接続します。

簡単に言うと条件に合わせてバッチを稼働したい場合に向いています。Azure FunctionなしでLog Analyticsからデータを収集しMonitorから条件を付けてスクリプトを実行する方法もありますが、この方法と比べて使うのもいいかと思います。

### [Azure App Service WebJobs](https://learn.microsoft.com/ja-jp/azure/app-service/webjobs-create)

App Serviceを使っている場合は機能の一つのWebジョブという機能が使えます。
決まった時間になるとWebAPIを起動するなどのWeb Appに含まれているコードを実行するのに最適されていますが、逆にほかのシステムの管理だどの機能をまとめて専用のWeb Appとして使うのも良いかと思います。

## 比較

### Microsoft Power Automate vs. Azure Logic Apps

Power Automate と Azure Logic Apps はどちらも、ワークフローを作成できる 
azurebatch.md: https://admin.powerplatform.microsoft.com
azurebatch.md: https://azure.microsoft.com/services/security-center/
azurebatch.md: https://azure.microsoft.com/blog/azure-audit-logs-ux-refresh/
azurebatch.md: https://azure.microsoft.com/solutions/serverless/
azureeventhub.md: https://learn.microsoft.com/ja-jp/rest/api/eventhub/send-batch-events)
- [Pythonを利用したイベント送信及び受信](https://learn.microsoft.com/ja-jp/azure/event-hubs/event-hubs-python-get-started-send?tabs=passwordless%2Croles-azure-portal)


![AzureEventHub drawio](https://github.com/LowyShin/KnowledgeBase/assets/20239203/e009bfaf-9a4a-4ff0-bad3-bda9efe843da)


### 疑似サービス比較

| サービス | タイプ | 目的 | 使用例 | 価格 | 
--|--|--|--|--|
| Azure Event Hubs | イベントストリーミング（持続配信） | ビックデータの持続送信 | ログ送信・データ送信 | $10.98/100万イベント | 
| Azure Event Grid | イベント配信 | 反応型開発 | Trigger Azure Functionsを利用した条件の開発 | $0.54/100万操作（10万操作まで無料）|
| Azure Service Bus | メッセージ | 企業型アプリケーションメッセージ処理 | オーダー処理、金融のバッチ処理、メッセージキュー、AMQP | $0.05/100万処理 | 

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/294f4194-4277-4d0a-9953-96dd582deb17)



### おまけ

設定が複雑なのでシンプルに状態をストレージアカウントに入れてチェックするのもありです。

1. Batchが終わったらバッチの順番をテキストファイル化してアップロードする
   - https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-upload-python
2. アップしたファイルを次のバッチがチェックしまだ前回のバッチが終了してなかったら1分待つ、の繰り返し。


networking.md: https://learn.microsoft.com/ja-jp/azure/architecture/example-scenario/web/media/multi-tier-app-service-private-endpoint.png)
- https://learn.microsoft.com/ja-jp/azure/architecture/example-scenario/web/multi-tier-app-service-private-endpoint




bash.md: https://github.com/LowyShin/KnowledgeBase/blob/master/dic/c/CentOS/README.md

bcrypt.md: https://laboratory.kazuuu.net/using-bcrypt-in-python-to-match-passwords-against-a-hash-value/)

ERC20.md: https://thirdweb.com/)


### Create ERC-20 Token Contract

独自トークンを発行してサービスに使いたい場合ERC20トークンを作成すると良いです。
PolygonもEVM Compatibilityに合ってるのでEthereum Walletの自分のアドレスをそのまま使えます。但し、PolygonネットワークがサポートされているWalletのみですね。

まずContractを作成しましょう。

- [+ Deploy contract]をクリック
![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/45e1c4d3-a0f2-4a1c-8e95-c8426034f830)

- ERC20 Standardと書いてあるトークンを選択します。
![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/52f11b90-9c48-4978-abec-dd6d33f709ea)

- 詳細がありますが、全て含まれているのでそのまま[Deploy now >>]をクリックしましょう。
![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/2522b6f5-a2d1-45e8-a701-d61a4fa7de70)

- イメージをアップしなくても良いですが、好きなロゴがあったらアップしてください。
- Nameにはトークンの正式名称を入れましょう。
- SymbolにBTCとかETHなどの縮約した記号を入れます。
- Descriptionにはこのトークンの詳細を入れましょう。公式ホームページがあったら入れた方がいいでしょう。
- Primary Sale Recipientには自分のWallet Addressを入れといたら最初発行する時自分に来ます。
- 終わったら下のネットワークを選択します。今回はPolygonのテストネットのMUNBAIを選択しました。
![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/1152ca41-04d4-4f20-bcfc-4fbeaff92d4b)
- 終わったら[Deploy Now]をクリックすると生成完了！

- 生成が終わったらContractsメニューから生成されたトークンが表示されます。
- まだ完成と書いてないでしょう。それはまだMintされてないからです。
- 作成したContractをクリックすると左のExtensionsにTokensメニューが表示されます。クリックしてみましょう。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/cbf6160a-a63c-4f0b-a954-e363c88d72c5)

[+ Mint]をクリックして発行量を決めましょう。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/9c2b4b4d-2ed3-4157-9f22-11ca7abf7922)

好きなほど入れましょう。

すると発行量が発行されたことが分かります。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/8a0a03eb-8ecb-4648-b9fb-7f59bc51a287)

polygonscanから見てみましょうか？

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/b70b8a97-5a23-4e4a-b0f0-16c2c85b7f74)

Contractの詳細が表示されます。
よくわからなかったら右にあるToken Trackerに表示されている自分のトークンをクリックしてみましょうか？

Total Supplyに正常に自分がMintした数量が表示されましたね！

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/bdced13e-382e-4dfa-b73e-2333ee833188)

これで成功です！

知り合いに伝送したいならTokensメニューから[Transfer]を利用して友達にあげてみましょう！




nftcol.md: https://thirdweb.com/

2. Contractsをクリックして[+ Deploy contract]をクリック

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/3aed7b30-1d5b-4f68-94ad-6debc099b7be)


3. NFTsセクションの[NFT Collection]をクリック

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/3e49c724-00b0-40db-92fd-4504ba4500e0)


4. Deploy Nowをクリック

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/ef92a6f2-409e-4771-a77b-ef95bd0c3786)

5. 情報入力

- Image : Contract詳細に表示されるアイコンです。
- Name : Contractの名称です。表示はこれがメインですね。
- Symbol : ERC20系なら数字の後ろに表示されますが、NFTではあまり表示されるところがないかと。
- Description : Contractの説明です。NFTの説明ではないので簡単に…。
- Royalties : ContractのオーナーのWallet Addressを入力してPercentageを入力するとこのContractから作ったNFTを取引する場合このアドレスに収益が支給されます。
- Primary Sales : これは販売者のWallet Addressです。
- ネットワークは好きなネットワークをしてください。私はPolygonのテストネットのMUNBAIを使ってます。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/54211e99-2fc1-4534-835d-56eeb1f5fe7b)

6. NFT Mint

作成完了したら[Contracts]メニューに入ったページの左にExtensions > NFTsが表示されます。クリックしましょう。

今作成したNFT Collectionが表示されてます。右側にある[+ Mint]をクリックしましょう。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/7ee49879-15a0-4e53-a23b-8f9c7d2a004a)

7. NFT情報入力

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/d5991b8b-34de-422b-96fa-6e4469641b6b)

- Name : このNFTの名称です。
- Media : このNFTのメインイメージです。
- Desciption : このNFTの説明です。
- Properties : このNFTの属性などのデータが入力できます。もし長いJSONファイルの場合trait_typeをdataと記入してvalueのところにあるアップロードボタンをクリックしてJSONファイルをアップすると入力できます。

8. 誰かにあげる

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/99acbbbc-a34c-4b1b-b0ae-8c45e09de37c)

作成したNFTをクリックすると詳細が表示されます。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/76edf410-2827-4b96-bc05-1ff907ec11ae)

詳細画面にTransferというタブをクリックしましょう。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/0017310c-c70b-42ca-bc5d-7deadd29c1a9)

ToAddressに送りたい人のWallet Addressを入力すると送信完了！



nftdrop.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/e8ab3aa3-d88c-42e8-8809-7b26ad27fd44)

2. PopularにあるNFT Dropを選択します。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/f737384b-8690-448d-bbb6-850e635c515e)

3. 詳細は分からないからそのまま[Deploy now >>]をクリックして早速作りましょう。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/ead440c2-628a-4c0c-bc87-fd7a49c79776)

4. Contractを作成するのはERC20と似てますが、Royaltiesというのがあって発行したNFTがどのように取引されても発行者にRoyaltyという利益が与えられます。
ほかにはERC20と同じなのでERC20編をご参考ください。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/fba39439-0bbd-4d3c-9bb1-67ed5c1b2f09)


5. NFTが作成されたら左側にNFTsメニューが表示されます。NFTsにNFTを登録しましょう。

- [+ Single Upload]を選択すると一つずつアップできます。
  - Name : NFT名を入力します。
  - Media : NFTの代表イメージを表示します。
  - Description : NFTの説明を入力します。
  - Properties : 無限に追加できますが、もしKey Value形式ではなくJSONなどの形式ならtrait_typeにdataと入力しvalueのところにファイルアップロードボタンをクリックしてファイル自体を登録することもできます。
  ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/163e9e26-f40c-4b4c-b939-782863b18e1c)
- [Batch Upload]を選択するとフォーマットをダウンロードしてフォーマットに合わせて入力し一気にアップすることも可能です。
  ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/f0f9ec88-0ffc-4e13-8dbc-01e9a20569fd)

6. 作成完了したらいつからもらえるかなどのCondition設定を行いましょう。

左メニューから[Claim Conditions]を選択します。

[+ Add Phase]をクリックして条件を登録します。クリックするとPublic, Public(With Allowlist), Allowlist Only, Only Ownerって表示されますが、誰でももらえるようにするために「Public」を選択しました。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/75c15135-6aa1-4c52-87c0-f160718f0b1a)

- Name : イベント名っていうかこのプロモーションのタイトルを記入します。
- When will this phase start? : 日時を入力するとその日時から配布が開始されます。
- How many NFTs will you drop in this phase : 今回のプロモーションでいくつのNFTを配布するかを数字で入力します。入力されたNFT数が超えたら終了する模様です。
- How much do you want to charge to claim each NFT? : 各NFTの価格を設定できます。無料なら０を入力すると無料配布できます。
- How many NFTs can be claimed per wallet? : 一人がたくさん申請することを防ぐために同じWalletにもらえるNFTが決まります。

![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/15a038d7-aa59-4a5a-b720-7999d9a2ab61)

[Save Phases]をクリックして保存すると準備は終わりました！

7. 次は時間になったらClaimを実行するAPIなどで呼び出すとオッケーですが、それからは開発ですね。頑張って！






nftimport-mm.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/619b98cc-6cdc-4e36-ab54-5444721d9eec)

2. NFTに移動

   ![metamask nft](https://github.com/LowyShin/KnowledgeBase/assets/20239203/77f89f1e-e7fc-4ac6-94b2-729f07f97b45)

3. NFTをインポートをクリック

   - 下にスクロールしないと見えないのでご注意

   ![metamask import nft](https://github.com/LowyShin/KnowledgeBase/assets/20239203/e98f5605-a235-4833-9196-c5a44464afe7)

4. Polygonscanに移動

   - NFT詳細を見るとTransaction Hashが表示されたらクリックすると情報が表示される。

   ![musubi - omamori detail ](https://github.com/LowyShin/KnowledgeBase/assets/20239203/1f2e2ed5-6026-438b-b864-fd09092e8a50)

5. Contract AddressとトークンIDをコピー

   ![polygonscan-contaddrcheck](https://github.com/LowyShin/KnowledgeBase/assets/20239203/5fc6c74c-eb2b-4011-a616-5b7e92a3648c)

6. コピーした内容を入れてインポートをクリック

   ![input contract and tokenid - metamask](https://github.com/LowyShin/KnowledgeBase/assets/20239203/ec023cb0-4ba6-4cba-be6d-9f5863c32572)

7. 表示確認

   ![nft list - metamask](https://github.com/LowyShin/KnowledgeBase/assets/20239203/e9b508da-3ef8-41df-b363-663768241a2a)




polygon.md: https://polygon.technology/)
- [Polygon Scan](https://polygonscan.com/)
- Deploy and management : [ThirdWeb - ERC Token management tool](https://thirdweb.com/thirdweb.eth/TokenERC20)

## Networks

### Polygon Mainnet

- Network Name：Matic mainnet
- RPC URL：https://rpc-mainnet.maticvigil.com/
- Chain ID：137
- Symbol：MATIC
- Block Explorer URL：https://polygonscan.com/

### Munbai Testnet

- Network Name: Mumbai Testnet
- New RPC URL: https://rpc-mumbai.maticvigil.com/
- Chain ID: 80001
- Currency Symbol: MATIC
- Block Explorer URL: https://polygonscan.com/

## ThirdWeb



sto.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/890c3071-de82-4d20-b608-0d4bc4bacf48)

기업등이 STO를 이용하여 발행한 주식, 사채, 수익증권, 집단 투자스킴 배분등이 규제 대상이 되어, 신탁수익권, 집단투자스킴배분 등의 금융법 제 2조2항 각호에 게재한 권리
(제2항 유가증권)을 토큰(전자정보 처리 조직을 이용하여 이전 할 수 있는 재산적 가치(전자기기 및 기타 전자적 방법에 의해 기록 된 것에 한함))에 표시한 것은, 
유통성이 높다고 예상되므로, 금융법상 새로운 [전자 기록 이전 권리]라고 정의되어, 종래의 제2항 유가증권이 아닌 [제1항 유가증권]으로 취급 되었다.

즉, 토큰을 발행할 때 이 토큰은 어떠한 가치를 가지고 어떻게 배분이 될 것인지를 기록한 경우 STO로서 인정을 받을 수 있다.

- 참조 : [セキュリティトークンに関する現状等について - 일본 STO협회](https://www.fsa.go.jp/singi/digital/siryou/20230606/2jstoa.pdf)https://www.fsa.go.jp/singi/digital/siryou/20230606/2jstoa.pdf


DevOutsourcing.md: https://www.vmogroup.jp/about-us/ceo-statement)

CDN.md: https://bunny.net/pricing/


| Region | Price |
| :---: | ---: |
| Europe & North America | $0.01 /GB |
| South America | $0.045 /GB |
| Asia & Oceania | $0.03 /GB | 
| Middle East & Africa | $0.06 /GB |


chatgpt.md: https://chat.openai.com/chat)


## Prompt

- [ChatGPTなどで使える文例集](https://prompt.quel.jp/)
- [ChatGPTから高度な回答を引き出すプロンプト文例集](https://www.softbank.jp/biz/solutions/smb/prompt/)
- [【決定版】ChatGPTのプロンプトテンプレート集279選](https://transcope.io/column/chatgpt-prompt-template)
- [ChatGPT PROMPT LIBRARY](https://ai.threewave.jp/)
- [알아두면 쓸모 있는 ChatGPT 숨어있는 프롬프트 명령어 팁(AWS생성형 AI)](http://charlychoi.blogspot.com/2023/06/chatgpt.html)

containerservice.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/6dd492f5-f995-4193-ac7b-6215c2f5f30b)

[わかりやすい「コンテナ技術の解説」](https://zenn.dev/esaka/articles/2d117655af1f03cf2444#%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E6%8A%80%E8%A1%93%E3%81%AE%E8%AA%95%E7%94%9F)

## 関連技術

- Docker
- [Kubernetes](https://github.com/LowyShin/KnowledgeBase/blob/master/dic/k/kuubernetes.md)
- [ACI](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/azure/aci.md)
- Amazon Container Service

countrycode.md: https://en.wikipedia.org/wiki/ISO_3166-1)
- [IETF Language Code(Wikipedia)](https://en.wikipedia.org/wiki/IETF_language_tag)


cracking.md: https://goldb.tistory.com/entry/%EB%B3%B4%EC%95%88%EB%B6%84%EC%84%9D-%EC%9B%B9-%EC%B7%A8%EC%95%BD%EC%A0%90-%EB%B6%84%EC%84%9D-%EB%8F%84%EA%B5%AC-Wapiti3)

## 모의 해킹 툴

모의해킹 사이트이며, 최근 보안 트렌드에 치중되있는 사이트입니다.

http://chall.stypr.com 



침투테스트 가상환경을 샌드박스 형태로 제공하여, 온라인상에서 모의해킹을 해볼수 있는 사이트

https://hack.me/

 

OWASP에서 웹 취약점 테스트를 위해 제공하는 VM웨어용 가상이미지 파일 다운로드 및 프로젝트 페이지

http://sourceforge.net/projects/owaspbwa/files/

 

온라인상으로 프로그래밍언어를 실행하고 컴파일할 수 있는 사이트

http://compileonline.com/

 

취약한 웹 어플리케이션 소스를 제공하는 사이트

http://www.dvwa.co.uk/

 

온라인 모의해킹 사이트

http://hack-me.org/index.php?p=home

 

OWASP 취약점을 바탕으로한 취약점 테스팅 가상환경

http://sourceforge.net/projects/vicnum/

 

리눅스, 아파치, PHP, MySQL의 보안을 학습하기 위한 가상환경을 제공

http://sourceforge.net/projects/lampsecurity/

 

웹취약점 테스트를 하기 위해 제작된 가상이미지

http://sourceforge.net/projects/websecuritydojo/

 

다양한 환경에서 악의적인 코드를 분석할 수 있는 가상머신

http://bruteforce.gr/honeydrive

 

웹취약점 테스트 환경을 제공하는 사이트

https://www.pentesterlab.com/exercises

 

웹해킹 전문가가 만든 침투테스트를 위한 가상 이미지

https://bechtsoudis.com/work-stuff/challenges/drunk-admin-web-hacking-challenge/

 

다양한 모의 해킹를 실습하고 트레이닝할 수 있는 기능을 제공하는 툴

http://sourceforge.net/projects/null-gameover/

 

SQL 인젝션을 테스트하고 실험해 볼 수 있는 환경(소스)를 제공하는 사이트

https://github.com/Audi-1/sqli-labs

 

침투테스트 환경을 제공(DVL)

http://sourceforge.jp/projects/sfnet_virtualhacking/downloads/os/dvl/DVL_1.5_Infectious_Disease.iso/

 

모의해킹 연습 사이트 링크 모음

http://chogar.blog.me/80130034776



모의해킹식 사이트 최근 보안 트랜드에 취중되어있음

https://chall.stypr.com

git.md: https://ghp_nnsj1ShqSXXXXXXXXXVAiTQfzXXXXxeP2@github.com/LowyShin/myrepo.git`


## tips

### Github + Slack

- [Github + Slack integration](https://github.com/integrations/slack)
```sh
# 처음에는 github에 어카운트 연결을 해야함.
/github signin
# Subscribe된 레포지터리 표시
/github subscribe list
# Subscribe 설정. commits:* 는 모든 브랜치의 커밋 표시. commits만 넣으면 디폴트 브랜치의 commit표시. 
/github subscribe LowyShin/KnowledgeBase commits:*
```

### .gitignore

node_modules를 실수로 인덱스 걸어버린 경우
```sh
# 인덱스에서 node_modules를 삭제
$ git rm -r --cached node_modules  

$ git status
On branch master
Initial commit
Changes to be committed:
  (use 
git.md: https://github.com/LowyShin/giipAgentLinux.sh
```

- git clone with branch
```sh
git clone -b main https://github.com/LowyShin/giipAgentLinux.sh
```

- get all branch list
```sh
git branch -a
```

- make a branch
```sh
git banch -b mybranch
```

* git pull
```sh
git pull origin master
```
* git push
```sh
git add .
git commit -m 
git.md: https://github.com/LowyShin/myrepo.git
git push -u --force origin master
```

### make branch

* https://qiita.com/TetsuTaka/items/5ab227a8bd2cd7106833
* git branch make
  * https://qiita.com/hinatades/items/d47dec72a87c5fed50f7
  * https://techacademy.jp/magazine/10264

* git history clear(reinit)
  *  https://gist.github.com/stephenhardy/5470814

## Management

### Check git

- git 레포지터리와 로컬을 비교해서 다른 경우 가져오는 스크립트
```sh
reponame=
git.md: https://www.christianengvall.se/check-for-changes-on-remote-origin-git-repository/


## Markdown

* Official : https://github.com/dotnet/docs/blob/master/styleguide/template.md#supported-languages

## Authentication

* vscode git basic credential logon failed
  * git application update 
    * `git update-git-for-windows`
  * reset windows auth
    * https://cpoint-lab.co.jp/article/201804/2137/
* [git credential problem(password change, initialize)](https://www.zunouissiki.com/entry/git-credential-manager-for-windows/)


google-apps-script.md: https://qiita.com/0Delta/items/7d8303eebbff4062069e)

- [How to Get the Sheet Name in Google Sheets (Formula)](https://spreadsheetpoint.com/get-sheet-name-google-sheets/)


## Links

* [Google Apps Scriptで値の変更をトリガーにしつつ変更されたセルの行番号と列番号を知る](https://tonari-it.com/gas-trigger-changed/#toc2)
* [スプレッドシートで特定の列のセルに色がついた時に、メールで通知がくるようにしたい](https://teratail.com/questions/295611)

* [GASでローカルCSVを取り込み、スプレッドシートで請求書を作成する](https://dev.classmethod.jp/articles/gas-ss-csv-create-invoice/)


hash.md: https://qiita.com/KEINOS/items/c92268386d265042ea16)

huggingface.md: https://huggingface.co/models](https://huggingface.co/models)

### **② 데이터셋 허브 (Datasets Hub)**
- 다양한 **NLP, CV, 오디오 데이터셋** 제공
- [https://huggingface.co/datasets](https://huggingface.co/datasets)에서 사용 가능

### **③ Spaces (AI 애플리케이션 배포)**
- Gradio와 Streamlit을 활용하여 **AI 모델을 쉽게 웹 앱으로 배포 가능**
- 무료로 AI 데모를 만들고 공유할 수 있음
- [https://huggingface.co/spaces](https://huggingface.co/spaces)

---

## **4. Hugging Face의 한계**
✅ **장점**  
- Transformer 모델을 쉽게 활용 가능  
- 방대한 오픈소스 모델과 데이터셋 제공  
- NLP, 이미지, 음성 등 다양한 도메인 지원  
- GPU, TPU에서 학습 가능  

❌ **단점**  
- 대형 모델(GPT-3, GPT-4 등)은 Hugging Face에서 직접 제공하지 않음 (OpenAI API 필요)  
- **대형 모델은 GPU 메모리 사용량이 많음** (Colab 무료 버전에서는 실행 어려움)  
- 최신 모델을 직접 학습하려면 고사양 하드웨어 필요  

---

## **5. 결론: Hugging Face는 Transformer 중심 플랫폼**
✔ Hugging Face는 Transformer 모델을 중심으로 **텍스트, 이미지, 오디오 처리**를 지원하는 AI 생태계  
✔ `transformers`, `datasets`, `diffusers` 등 강력한 라이브러리를 제공  
✔ 누구나 Transformer 모델을 **쉽게 사용하고, 배포하고, fine-tuning 가능**  
✔ **AI 연구자, 개발자, 기업 모두에게 필수적인 플랫폼** 🚀

즉, Hugging Face는 **Transformer 기반 AI를 쉽고 강력하게 활용할 수 있도록 지원하는 최고의 플랫폼**입니다!

Cisco.md: https://www.cisco.com/c/ja_jp/products/collateral/switches/catalyst-3850-series-switches/data_sheet_c78-720918.html)
* cisco ws-c3850-24T-S : 24port 1G L3
* [cisco catalyst ws-c2960s-24ts-s](https://www.cisco.com/c/ja_jp/products/collateral/switches/catalyst-2960-series-switches/product_data_sheet0900aecd806b0bd8.html)
* cisco catalyst ws-c2960xr-24ts-L/LL
* [cisco catalyst ws-c2960xr-24td-L/LL](https://www.cisco.com/c/ja_jp/products/collateral/switches/catalyst-2960-x-series-switches/data_sheet_c78-728232.html)

bike.md: https://www.bikebros.co.jp/vb/)

EBike.md: https://guides.wiggle.jp/%E3%83%9E%E3%82%A6%E3%83%B3%E3%83%86%E3%83%B3%E3%83%90%E3%82%A4%E3%82%AF%E3%82%BF%E3%82%A4%E3%83%A4%E3%82%AC%E3%82%A4%E3%83%89)

iphonese20220325.md: https://kakakumag.com/pc-smartphone/?id=18152&lid=mail_220325_top01)
  * 「A15 Bionic」搭載で5Gにも対応！不満の声があったバッテリー駆動時間は2時間アップ

Lithium-ion-Battery.md: https://ja.wikipedia.org/wiki/%E3%83%AA%E3%83%81%E3%82%A6%E3%83%A0%E3%82%A4%E3%82%AA%E3%83%B3%E4%BA%8C%E6%AC%A1%E9%9B%BB%E6%B1%A0)

* 九州電力電気代計算
  * https://enechange.jp/articles/kyushu-plan-saving

kuubernetes.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/af9f7517-74bc-401e-bcc6-d3bfef430cad)


## Kubernetesが開発された経緯

Kubernetesは、コンテナ化されたアプリケーションを大規模にデプロイし管理するという課題に対処するために開発された。Kubernetesが開発される以前は、コンテナを大規模にデプロイし管理することは、複雑で手動のプロセスであり、多くの労力と専門知識が必要だった。

確かに、DockerはWeb開発において便利である。しかし、本番環境において使用するには、Dockerの場合だと基本的に1つのコンテナにつき1つの機能しか実行できないことがある。よって、複雑なアプリケーションを構築する場合には、複数のコンテナを必要とする。では、どのように構築すべきだろうか？

例えば、Docker Composeを用いた場合を考えてみよう。しかしながら、複数のコンテナを1つのサーバーに収めることができないため、どのコンテナがどのサーバーにあるか管理しなければならない。また、コンテナが停止した場合には、すみやかに復旧できるようにしなければならない。さらに、複数のサーバーを跨いだコンテナ間の通信は複雑であるため、注意を払う必要がある。

また、コンテナを更新する場合には、コンテナ間の依存関係やデプロイの順序などを考慮しなければならない。さらに、複数のサーバーにコンテナがある場合には、ロードバランシングも必要となる。また、サーバーのスケーリングも必要となる。各コンテナからはログが出力されるものの、これらを適切に管理しなければ運用が困難となることもある。

このようなタスクは、Kubernetesであれば解決できる。

要は、Kubernetesは、移植性、拡張性、柔軟性に優れており、オンプレミスのデータセンターからパブリッククラウドまで、さまざまな環境で使用できるように設計されている。Kubernetesは、最新のアプリケーション開発とデプロイメントに不可欠なツールとなっており、企業は複雑な分散アプリケーションを容易に構築・管理できるようになった。

## Kubernetesが使われる理由

Kubernetesは現在のWeb開発で使われている理由は、主に以下の様な特徴を持っていることにある。

- スケーラビリティが高い：Kubernetesは、クラウドネイティブなアプリケーションを構築するためのプラットフォームであり、スケーラビリティが非常に高いため、急激なトラフィックの変化にも柔軟に対応できる。KubernetesはWindows、macOSやLinuxどれも対応している。
- アプリケーションのデプロイ自動化と管理が得意：Kubernetesは、アプリケーションの自動化されたデプロイと管理を可能にするための機能を提供しており、DevOpsチームがアプリケーションの展開と管理にかかる時間を大幅に短縮することができる。
- ポータビリティが高い：Kubernetesは、複数のクラウドプロバイダーとオンプレミス環境で動作するため、アプリケーションをどこでも実行できるようになる。これにより、ベンダーロックインのリスクを軽減し、アプリケーションのポータビリティを高めることができる。
- マイクロサービスのサポート：Kubernetesは、マイクロサービスアーキテクチャを採用したアプリケーションの開発と管理を簡単にするための機能を提供している。これにより、アプリケーションを小さなサービスに分割し、それぞれのサービスを個別に展開および管理することができる。
- 障害に強い：Kubernetesは、高可用性のための冗長性を提供するために、複数のノードにアプリケーションをデプロイできる。また、障害が発生した場合には、自動的に障害のあるノードからアプリケーションを再スケジュールすることができる。

これらの特徴により、Kubernetesは現在のDevOpsを実現する上で非常に強力なプラットフォームだといえよう。

- [分かりやすい「僕らは何故Kubernetesを使うのか」](https://zenn.dev/esaka/articles/2d117655af1f03cf2444)

## Kubernetesの強み

- 多種多様なワークフローに対応できるほど機能が豊富
- 宣言的設定と突き合わせループでリソースを管理できる
- 幅広いデプロイ形式のサポート
- 拡張性が高い

## 用語

- Cluster
  - Kubernetesのリソースを管理する集合体。Master Nodeと複数のNodeから構成される。
- Node
  - Kubernetesのリソースの中で最も大きな概念。
- Pod
  - コンテナの集合体。Nodeの中で動作し、１つ以上のコンテナを持っている。原則、Kubernetesでコンテナを運用・管理する際にはPod単位で行う。Kubernetesにデプロイする際には、Pod単位で実施する。
- Deployment
  - Podを管理する方法を定義する。
- DaemonSet
  - クラスタが動作するサーバ１つにつき、必ず１つは起動させたいPodを定義する。
- Job
  - 処理を行って終了するようなPodを定義する。
- CronJob
  - JobリソースをCronのように定期的に変更する
- Service
  - 外部やクラスタ内からのリクエストをPodに割り振るようなネットワーク定義。
- ConfigMap
  - 環境変数等、Podで利用する設定を定義する。
- Secret
  - パスワードやトークン情報等、Podで利用する設定を定義する。
- Volume
  - Podで利用するストレージを定義する。

README2.md: https://kafka.apache.org/documentation/  
https://epicdevs.com/17  

## Introduce
링크드 인에서 개발된 분산 메시징 시스템으로 대용량의 실시간 로그처리에 특화된 아키텍쳐

지금도, 앞으로도 시스템은 점점 커져가고 있음

이로 인해 시스템 복잡도가 증가하게 되고 이에 따라 운영 업무에 시간이 많이 필요하게 되며 장애 발생은 예외 상황이 아닌 당연히 일어날 수 밖에 없게 되므로 복구 시간도 많이 필요하게 됨

각각의 전송 영역을 하나의 통합된 전송 영역으로 바꾸어 성능과 시간을 개선하기 위한 방법

## Structure
1. 메시지를 특정 수신자에게 직접 보내는 방식이 아님
    * 데이터 생산(Producer)과 데이터 소비(Consumer)가 서로 독립적인 관계임
      >Producer는 메시지 생산(Push)만 하고 Consumer는 메시지를 가져와서(Pull) 처리만 하므로 Consumer는 최적의 성능을 낼 수 있음
    * 메시지 처리가 Pull이므로 Batch처럼 사용할 수도 있음
2. 메시지를 메모리 큐에 적재하는게 아닌 디스크에 순차적으로 저장함
    * 장애가 발생해도 데이터 유실 가능성이 없음
    * 디스크 IO가 줄고 성능이 올라감
    * 처리되지 않은 메시지가 많아도 성능 감소가 없음
    * 처리된 메시지를 일정 기간 동안 삭제하지 않기 때문에 문제가 발생해도 재처리가 가능
3. 분산, 복제 구성이 용이함
4. TCP기반의 프로토콜로 인해 오버헤드가 높지 않음


## Topic, Partition
1. Producer는 Topic의 메시지를 생성하고 Broker에 전달
2. Broker가 받은 메시지를 Topic별로 분류, 관리
3. Consumer가 필요한 Topic의 메시지를 가져가서 처리

대략적인 구조는 이러함

Topic은 파티션 단위로 나뉘어 클러스터의 각 서버에 분산돼 저장

리플리케이션 설정이 되어있다면 파티션 단위로 각 서버에 분산돼 복제되고 장애 발생 시 파티션 단위로 Fail Over가 수행

각 파티션은 0부터 1씩 증가하는 오프셋 값을 메시지에 매칭하므로 파티션 번호와 오프셋으로 메시지를 식별

* 파티션 분산

  메시지를 전달할 때 어떤 파티션으로 전송할 지는 사용자가 지정한다
  >균등히 분배해 저장한다던지, 알파벳으로 시작하는 메시지는 한 파티션에만 저장하고 나머지 메시지는 다른 파티션에 저장한다던지

* 파티션 복제

  파티션을 복제하고 클러스터에 분산시킬 수 있음

  각 파티션에 대한 읽기, 쓰기 작업은 Leader에서 담당하고 Follower는 Leader 복제만 함

  그러다 Leader에 문제가 발생하면 Follower 중 하나가 Leader가 됨

  하나의 Leader가 읽기, 쓰기를 같이 해도 Broker에서 Leader를 분산시켜 놓기 때문에 부 하가 높지 않음

## Consumer, Consumer Group




## File System
메시지를 메모리가 아닌 디스크에 저장하기 때문에 메시지가 JVM 객체로 변환되며 크기가 커지는 것을 방지하고 가비지컬렉터로 인한 성능 저하도 방지

하드디스크의 순차적 읽기 속도는 메모리 랜덤 읽기 속도보다 빠를 정도로 높기 때문에 하드디스크를 사용하더라도 성능 유지가 됨

또한 관리를 OS에 위임하기 때문에 캐시를 효과적으로 사용가능

네트워크 전송 시에 zero-copy 방법을 사용하기 떄문에 데이터 전송 성능이 좋음


iis.md: https://www.ipentec.com/document/windows-10-install-internet-information-services)

landing.md: http://lp-web.com/)


languagecode.md: https://en.wikipedia.org/wiki/IETF_language_tag)
- [ISO_3166-1 Country Code(wikipedia)](https://en.wikipedia.org/wiki/ISO_3166-1)

lineapi.md: https://developers.line.biz/ja/docs/messaging-api/)

## samples

- [Node.jsとHerokuでLINE Bot Webアプリの開発](https://www.xgeek.net/ja/salesforce/build-line-bot-web-application-with-node-js-and-heroku/)https://www.xgeek.net/ja/salesforce/build-line-bot-web-application-with-node-js-and-heroku/

linestamp.md: https://gaiax-socialmedialab.jp/qa/difference-line-official-stamp-creators-stamp/)

・デフォルト無料スタンプ

デフォルト無料スタンプとはLINEが制作し、アプリインストール直後のデフォルト状態で利用できるスタンプです。

・有料販売スタンプ

有料販売スタンプとは、LINE、またはLINE以外の企業やブランドが制作し、有料で販売されているスタンプです。

・プロモーションスタンプ

プロモーションスタンプとは、広告主がユーザーに条件付きで提供しているスタンプです。

・クリエイターズスタンプ

クリエイターズスタンプとは「LINEクリエイターズマーケット」で販売されているスタンプで、審査を通れば誰でも販売可能なスタンプです。


- [企業のLINEクリエイターズスタンプ活用！作り方、配信方法、企業活用事例まとめ](https://gaiax-socialmedialab.jp/post-55390/)https://gaiax-socialmedialab.jp/post-55390/

- Linestamp Business Guide(pdf)
  - https://www.linebiz.com/sites/default/files/media/jp/download/LINE%20Business%20Guide_202207-09.pdf#page=35
 
- [LINEスタンプ申請について](https://line-stamp.jp/howto/5751/)https://line-stamp.jp/howto/5751/

rentalhouse.md: https://uchicomi.com/assets/img_rent_webp/r8_05b2164eb745bd50d501538fc9b51c64_c15c28c3f2c6c3f06a23b1983af48167.jpg.webp)
![madori](https://uchicomi.com/assets/img_rent_webp/r8_37cca51745531ee765f346cfc2c28420_4d57733076a2eb3af95747c9f9bc74bf.jpg.webp)
* https://uchicomi.com/chintai/kanto/chiba/12218/b24333/r60263/
  * 賃料：25,000円（管理費：3,000円）　
  * 敷金/礼金：敷金0/礼金0　
  * 間取り：1K（17.30m2）

### エンジェルハイツ５ 202（千葉県茂原市）
![angelhaitsu](https://uchicomi.com/assets/img_rent_webp/r8_dadd92ef29a810e6747b49caf7fe862a_b073cdf9e70f8e6f5913accdc4020af6.jpg.webp) 
* https://uchicomi.com/chintai/kanto/chiba/12210/b10514/r58322/
  * 賃料：37,000円（管理費：3,000円）　
  * 敷金/礼金：敷金0/礼金0　
  * 間取り：2DK（40.00m2）

### アビタシオン 202（千葉県茂原市）
![abitasion](https://uchicomi.com/assets/img_rent_webp/r8_26e2c9678ffc9bad5c62418b75304d03_3d34d27dd1164e7e5b4c1ef0688a5a4d.png.webp)
* https://uchicomi.com/chintai/kanto/chiba/12210/b19139/r48841/
  * 賃料：38,000円（管理費：2,000円）　
  * 敷金/礼金：敷金0/礼金0　
  * 間取り：2DK（36.00m2）



Sharehouse.md: https://akanegumo172.hatenablog.com/)
  * 福岡でお世話になったシェアオフィスですが、大家さんが個人的に運営しているので暖かい雰囲気の一戸建てのシェアハウスです。
  * 大家さんがイベントが好きで色んなパーティーなどを開いたりして楽しいです。


MySQL-Replication.md: https://dba.stackexchange.com/questions/45487/what-is-the-best-way-to-recover-from-a-mysql-replication-fail)

* [MySQL Replication fail](https://dba.stackexchange.com/questions/45487/what-is-the-best-way-to-recover-from-a-mysql-replication-fail)

### Ref

* Knowledgebase
  * https://github.com/LowyShin/KnowledgeBase/wiki

* for edit page
  * https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/MySQL/MySQL-Replication.md



mysqlbackup.md: https://developers.cyberagent.co.jp/blog/archives/28454/


nodejs-study.md: https://developer.mozilla.org/ko/docs/Web/JavaScript): JavaScript 문법과 개념을 자세히 설명.
   - [JavaScript.info](https://javascript.info/): JavaScript의 기초부터 심화까지 폭넓게 다룸.

2. **Node.js 학습 자료**
   - [Node.js 공식 문서](https://nodejs.org/ko/docs/): Node.js의 기능과 API를 이해할 수 있음.
   - [The Odin Project - Node.js](https://www.theodinproject.com/paths/full-stack-javascript): 초보자를 위한 Node.js 및 Express.js 강좌.

3. **YouTube 강좌**
   - [Traversy Media - Node.js Crash Course](https://www.youtube.com/watch?v=fBNz5xF-Kx4): 초보자를 위한 1시간 Node.js 강의.
   - [Nomad Coders - Node.js 강좌](https://nomadcoders.co/nodejs): 한국어로 진행되는 Node.js 강의.

4. **무료 프로젝트 템플릿**
   - [GitHub Node.js 예제](https://github.com/sindresorhus/awesome-nodejs): Node.js 관련 유용한 프로젝트와 자료 모음.

---

### **3. 추천 실습**
- 간단한 
README-jp.md: https://github.com/coreybutler/nvm-windows

```sh
# Installed Node List
nvm list

# node 16 latest install 
nvm install 16

# change node
nvm use 16

# check version
node --v
```

### RHEL(Red Hat Enterprise Linux)

Install nodejs 16 version
```sh
dnf module -y install nodejs:16

# Check version
node -v
```

- Install Yarn
```sh
curl -sL https://dl.yarnpkg.com/rpm/yarn.repo -o /etc/yum.repos.d/yarn.repo

dnf install -y yarn
```


### CentOS

```sh
curl -fsSL https://rpm.nodesource.com/setup_16.x | sudo bash -
sudo yum install -y nodejs

# remove previous version of nodejs when conflict latest version
yum remove nodejs
yum clear all
```

## Management

### Nodejsで作ったプロジェクトをgithubにアップしたらCI/CDのようにバックグラウンドで実行する

普段はnodejsをサービスとして実行する追加モジュールをインストールするかjenkinsなどを利用する方法がありますが、
giipを利用して簡単に実装ができます。

1. giip登録及びLogical Server作成
   - https://github.com/LowyShin/giipdoc-ja/wiki/Quickstart
2. giipAgentLinuxをサーバーに登録
   - 1番手順のリンクにgiipAgentLinuxの登録手順が含まれてます。
3. git cloneでソースのダウンロード
   - git cloneコマンドを利用してサーバーからソースをダウンロードします。
   ```sh
   mkdir -p /usr/projects
   cd /usr/projects
   git clone https://github.com/LowyShin/myprj.git
   ```
   - git cloneから権限などの問題が発生したらssh-keyを登録する必要があります。
     - https://github.com/LowyShin/KnowledgeBase/blob/master/dic/g/git.md#account   
   - ソース位置とスクリプトの位置を合わせる必要がありますが、面倒だったら`mkdir -p /usr/projects`にしたらサンプルと同じ位置になります。
4. nodeを起動するスクリプトを作成
   - https://github.com/LowyShin/giip/blob/gh-pages/giipscripts/sh/nodejs-githubsyncandrun.sh
   - 上記のリンクのソースをそのままコピーし[Automation > AddScript](https://giipasp.azurewebsites.net/view/SMAHTML/ScrPut.asp)に登録します。
   - 登録方法は1番手順にあるQuick Startの[サーバー情報取得スクリプトの登録]をご参考ください。 
   - 起動しなかったらイシューに環境をお教え頂ければご対応致します。
5. 作成したスクリプトをサーバーに割り当て
   - Quick Startの手順３から作成したスクリプトを登録して割り当てます。
6. サーバーからログ確認
   - サーバーにssh接続後下記のコマンドから実行状況がリアルタイムで確認できます。
   - `tail -f /var/log/giipAgentYYYYMMDD.log`
   ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/2691989d-5ba3-4ca0-a284-21d65d947279)
   - スクリプトは強制実行ボタンがあり、クリックすると待たずに実行できます。
   ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/905bfc03-c719-49ac-9d7a-595556bb3ef8)

登録したらDAEMONなどのプロセスなしでsshコンソールは閉じてもプロセスがバックグラウンドで稼働中になります。
バックグラウンドにするためのなんの追加リソースも要りません。
そして、状態情報はKVSに自動登録されるためサービスの状況が把握できます。
スクリプトにプロセスが落ちたら自動的に起動するようになっているのでチェック周期だけ調整すればオッケーです。
ソースが変わった場合`yarn install`が自動実行され、インストールが終わったら`yarn build`でビルドしてプロセスを起動するようになってます。

サーバーが変わったとしてもそのままリストアしたり、giipAgent.cnfをそのまま持っていけばなんの修正もなしで運用が続けられます。

しかし、Auto Scaleなどでサーバーが自動に増える場合は増えたサーバー中1台のスクリプトが稼働するためその時はLogical Machineを追加するか
サーバーが実行したら他のサーバーにもアップするように再登録するなどのAPIを組む必要があります。

### NODE_ENV on Windows

nodejsのNODE_ENV, SET_ENV等Linux shellからの環境変数がWindowsでも読めるにはwindows bashが必要。
大体の場合gitをインストールしているためgit bashを利用して設定するのが楽

```sh
npm config set script-shell 
README-jp.md: https://evantay.com/docs/nodejs-set-npm-run-shell/


## nodejs上で動くFramework

* [Flutter](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/flutter)
  * nodesjからインストールできるWeb/Android/iOSを一気に開発できるツール。コードの修正があまりいらなくnodejsからの様々な追加機能の活用ができる。
* [Vue.js](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/vue)
  * Front Web向け。SEO対策などが柔軟にできて反応が早い。
* [Nuxt.js](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/nuxtjs)
- [Nest.js](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/nestjs)

## Ref

* [node.js html内のjsファイルの読み込み](https://www.naka-sys.okinawa/nodejs-html-include/)
* [ゼロからはじめるExpress + Node.jsを使ったアプリ開発](https://qiita.com/nkjm/items/723990c518acfee6e473)
* [Node.js入門](https://www.tohoho-web.com/ex/nodejs.html#hello_web)


omamori.md: https://ja.wikipedia.org/wiki/%E3%81%8A%E5%AE%88%E3%82%8A))

## お守りサービス

- [結・MUSUBI：一緒に願いあうお守りコミュニティサービス](https://www.musubi.green)




openshift.md: https://github.com/LowyShin/KnowledgeBase/assets/20239203/d62e1aaa-cccf-40c1-ba74-22d1275d22dc)


## サポートイメージ

OpenShift Container Platformは60種類近くのイメージをサポートしています。
Jenkins、Httpd、node、Elasticsearch、Ruby、PHP、Perl、Python、.NET、MySQL、MariaDB、MongoDBなど主要なコンテンツにはほとんど対応しています。より詳細な内容については以下のURLを参考にしてください。

https://access.redhat.com/articles/2176281

## 機能

OpenShiftではKubernetesで実装されている機能が利用できることに加えて独自のコンポーネントを備えています。

- Integrated Docker Registry
OpenShiftではDocker imageを内部で保持します。そのためのリポジトリがIntegrated Docker Registryです。

- Software Defined Network
この機能を用いることで、サーバをまたいだコンテナ間の通信を一つのオーバレイネットワーク上で利用するシングルテナントか、プロジェクトごとにオーバレイネットワークを分けるマルチテナントで構成することできます。

- Build Configuration
Docker imageを作成するための設定です。

- Deployment Configuration
Kubernetesを拡張したコンテナ型アプリケーションのデプロイするための設定です。

- Source to Image
既に存在するコンテナイメージに別のソースコードからビルドしたアプリケーションをデプロイし、新しいDocker imageを作成します。

- Image Stream
OpenShiftがビルドしたDocker image、外部のDocker imageへのポインターを保持します。

- Route
OpenShift上で動作しているアプリケーションをURLでアクセスできるようにします。


openssl.md: https://slproweb.com/products/Win32OpenSSL.html

initora.md: https://www.projectgroup.info/tips/Oracle/Oracle_110001.html
  * `alter profile default limit password_life_time unlimited;`
  * change expired user's password

ORA-ActiveDuplicate.md: https://rameshoradba.blogspot.com/2016/04/db-refresh-with-rman-duplicate-command.html)


* [Oracle Replication Products](https://cosol.jp/techdb/2020/05/oracle-replication-methods-support-status/)

* [Data Guard replication setting](https://udonsoba.hatenablog.com/entry/2016/06/28/172736)

* [4種類のRMAN DUPLICATEでそれぞれ実際にデータベースをコピーする](https://qiita.com/tlokweng/items/a041394e1011434eca06)
* [Duplicate from Active database](https://qiita.com/plusultra/items/51f661836828b3765d4b)

* [DataGuard構築後に使うSQLコマンドまとめ（逆引き）](https://www.ashisuto.co.jp/db_blog/article/20160831_dataguard_sql.html)

* [Dataguard status](https://dbtut.com/index.php/2020/01/30/how-to-check-data-guard-status/)
  ```sql
  -- from slave database
  https://dbtut.com/index.php/2020/01/30/how-to-check-data-guard-status/
  ```

* [Dataguard sql reference](https://www.ashisuto.co.jp/db_blog/article/20160831_dataguard_sql.html)
  ```sql
  -- check master setting
  SELECT DEST_NAME,RECOVERY_MODE FROM V$ARCHIVE_DEST_STATUS WHERE TYPE = 'PHYSICAL';
  -- check slave setting
  SELECT PROCESS,STATUS FROM V$MANAGED_STANDBY WHERE PROCESS LIKE 'MRP%';
  ```


* [RESTORE AND RECOVER STANDBY DATABASE FROM NETWORK SERVICE  ](https://oracledbatr.blogspot.com/2019/01/12c-new-feature-restore-and-recover.html)

oracle-instantclient.md: https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html


## ORACLE instant client inatall on CentOS using yum

1. Update yum repository
```sh
cd /etc/yum.repos.d
wget http://yum.oracle.com/public-yum-ol7.repo
```
2. import GPG key
```sh
wget http://yum.oracle.com/RPM-GPG-KEY-oracle-ol7
rpm --import RPM-GPG-KEY-oracle-ol7 
```

3. Enable oracle instantclient repository
```sh
yum install -y yum-utils
yum-config-manager --enable ol7_oracle_instantclient
```
4. yum install
```sh
yum -y install oracle-instantclient19.3-basic oracle-instantclient19.3-devel oracle-instantclient19.3-jdbc oracle-instantclient19.3-sqlplus
```
5. check installed packages
```sh
yum list oracle-instantclient*
```

6. set environment
```sh
echo 
oracle-instantclient.md: https://github.com/LowyShin/KnowledgeBase/wiki)
  * [ORACLE](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/ORACLE)
    * [Basic Management](https://talklowy-jp.blogspot.com/2020/10/oracle-management-knowledge.html)
    * [Installation](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/ORACLEInstallTips)
    * [InstantClient](https://talklowy-jp.blogspot.com/2021/10/oracle-linuxcentos-instant-client.html)
    * [DDL](https://talklowy-jp.blogspot.com/2020/10/oracle-ddl-lowy-knowledgebase.html)
    * [ORACLETuning](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/ORACLETuning.md)
    * [Merge Into/Update Join](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/MERGE.md)
    * [Useful SQL](https://talklowy-jp.blogspot.com/2020/10/oracle-useful-sql.html)
    * [TableSpaceManagement](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/tablespace.md)
    * [datetime](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/ORAdatetime.md)
    * [Flashback](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/ORAFlashback.md)
    * [BackupRestore](https://talklowy-jp.blogspot.com/2021/02/oracle-backup-and-restore-lowy.html)
    * [Replication](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/ORAReplication.md)
    * [Characterset(Official)](https://www.oracle.com/technetwork/jp/content/charcterset-250314-ja.pdf)
    * [DBMS STAT](https://github.com/LowyShin/KnowledgeBase/blob/master/wiki/ORACLE/ORADBMSSTAT.md)

* [for Edit](https://github.com/LowyShin/KnowledgeBase/edit/master/wiki/ORACLE/oracle-instantclient.md)



ORACLETuning.md: https://www.zanmai.net/blog/data/252.html
```sql
SELECT 
	a.owner
	, a.table_name
	,a.num_rows
	, b.MB
FROM all_tables a
      , (Select Segment_Name,Sum(bytes)/1024/1024 MB From dba_segments Group By Segment_Name) b
WHERE a.table_name = b.Segment_Name
ORDER BY b.MB desc, a.num_rows desc;
```
if you can not see row number, execute below system procedure gather_table_stat

* FInd table owner and size(rownum) check
```sql
select OWNER, TABLE_NAME, TABLESPACE_NAME, NUM_ROWS, TABLESPACE_NAME
from all_tables 
where TABLE_NAME in ('<Table name>')
;
```

* Execute if NUM_ROWS is null of above SQL
```sql
exec dbms_stats.gather_table_stats('<Owner>', '<Table Name>');
```

* Find column name from all tables
```sql
select * 
from all_tab_columns
where column_name like '<Column Name>'
;
```

* Get index info
```sql
select * from all_indexes
where TABLE_NAME in ('<Table Name>')
;

select * from all_ind_columns
where INDEX_NAME in (
    select INDEX_NAME from all_indexes
    where TABLE_NAME in ('<Table Name>')
    )
order by TABLE_NAME, INDEX_NAME, COLUMN_POSITION
;
```
* Put plan table
```sql
explain plan for
select AAA, count(1) from TABLENAME group by AAA;

select * 
from PLAN_TABLE
where to_char(TIMESTAMP, 'YYYYMMDDHH24MISS') in (select MAX(to_char(TIMESTAMP, 'YYYYMMDDHH24MISS')) from PLAN_TABLE)
order by PARENT_ID, ID
;
```

### Tuning information

* DWH tuning, Query statistics (jp)
  * https://www.oracle.com/jp/technical-resources/articles/pickup.html

### Database movement

* Oracle 11g movement Notes
  * https://talklowy-jp.blogspot.com/2020/07/oracle_29.html

### Lock management

* Lock mode explain and solution
  * (ja) https://www.ex-em.co.jp/oracle-k/oracle-event-%E8%A7%A3%E8%AA%AC/889/
* Lock mode description
  * (ja) https://www.shift-the-oracle.com/lock-event-enqueue/table-lock-matrix.html

### free buffer waits 

* https://www.ex-em.co.jp/oracle-k/oracle-event-%E8%A7%A3%E8%AA%AC/1266/free-buffer-waits/
* https://magnusjohanssontuning.wordpress.com/2017/09/05/free-buffer-waits/

```sql
select filetype_name, asynch_io, count(1)
from v$iostat_file
group by  filetype_name, asynch_io;
```

* https://oracle-base.com/articles/misc/direct-and-asynchronous-io

```sql
SHOW PARAMETER FILESYSTEMIO_OPTIONS

ALTER SYSTEM SET FILESYSTEMIO_OPTIONS=SETALL SCOPE=SPFILE;
SHUTDOWN IMMEDIATE
STARTUP

show parameter db_cache_size;
-- db_cache_size                        big integer 0
```

* http://www.nazmulhuda.info/buffer-cache-tuning
```sql
select name,value
from v$sysstat where name='free buffer inspected';

/*
select event,total_waits
from v$system_event
where event in ('buffer busy waits');
*/

show parameter sga;

SHOW PARAMETER buffer
-- log_buffer                           integer     9322496
-- alter system set log_buffer = 20M

select event, total_waits, time_waited
from v$session_event
where sid = (select sid from v$mystat where rownum = 1)
order by 3 desc;

```

* ulimit change
  * https://alpha-netzilla.blogspot.com/2012/12/parameter-user.html
  * see all : ulimit -a
  * change : ulimit -l unlimited -> max locked memory
  * /etc/security/limits.conf

* [ORACLE tablespace defragmentation](https://blog.toadworld.com/tablespaces_-_defragmenting)
* [[SQL] '%'や'_'をLIKE検索する](https://oracle.programmer-reference.com/sql-like-percent-underbar/)

* [Oracle DataPump](https://qiita.com/plusultra/items/0510587dc052ac4c0875)
* Oracle expdp:ORA-31634: job already exists
  * https://www.twblogs.net/a/5c237063bd9eee16b3db454f
  * https://www.code-lab.net/?p=21850
* [Oracle expdp usage](https://sql-oracle.com/?p=183)
* [ORACLE rman example script](https://qiita.com/shione/items/adcc6b9730e4b4f6f640)
* [oracle archive log activate](https://www.sql-dbtips.com/architecture/log_mode/)
  * `select log_mode from v$database;`
* [rman incremental tablespace backup and restore redundant server](https://zatoima.github.io/oracle-jpoug-migration-database.html)
* [rman move tablespace](https://cosol.jp/techdb/2019/12/love_rman_jpoug_advent_calendar_2019_1st_day/)
* [rman duplicate active database](https://qiita.com/tlokweng/items/a041394e1011434eca06)
* [rman backup incremental](https://cosol.jp/techdb/2019/12/love_rman2_ultra_fast_oracle_recovery/)
* [rman archive log delete command](https://it-memo.info/?p=1413)
* [drill down rman backup and schedule](https://www.slideshare.net/oracle4engineer/rman-44068359)
* [rman example script](https://qiita.com/shione/items/adcc6b9730e4b4f6f640)
* [ORACLE awr report](https://hackaday.hatenablog.com/entry/2019/12/14/082747)
* [ORACLE DDL](https://siguniang.wordpress.com/2013/09/04/oracle-dbms_metadata-get_ddl-fetch-ddl-for-tables/)
* [ORACLE DDL PACKAGE](https://qiita.com/Papageno/items/5b3159ec1a3b0e9db9ed)
* [oracle - instr](https://www.shift-the-oracle.com/sql/functions/instr.html)
* [oracle - regex substr](https://www.shift-the-oracle.com/sql/functions/regexp_substr.html)

* [書式モデル(数値)](https://www.shift-the-oracle.com/sql/number-format-element.html)
* [group by rollup, cube](https://qiita.com/q1701/items/2321b9a8674d9796af5b)
* [Oracle DDL Script List](https://oracle-base.com/dba/scripts)
  * [oracle - user ddl script](https://oracle-base.com/dba/script?category=script_creation&file=user_ddl.sql)
  * [oracle - trigger ddl script](https://oracle-base.com/dba/script?category=script_creation&file=table_triggers_ddl.sql)
  * [oracle - table constraint ddl script](https://oracle-base.com/dba/script?category=script_creation&file=table_constraints_ddl.sql)
* [oracle - tnsnames.ora sample](https://qiita.com/tajihiro/items/13322c89ac5904d0ce2f)

ORADBMSSTAT.md: http://www.doppo1.net/oracle/script/statistics.html
* https://shimi-dai.com/oracledb-gather-statistics/

ORAFlashback.md: https://atmarkit.itmedia.co.jp/ait/articles/0811/27/news141_2.html)


ORAFlushBufferCache.md: https://www.shift-the-oracle.com/linux/utility/flush-buffer-cache.html
```sh
echo 1 > /proc/sys/vm/drop_caches
echo 2 > /proc/sys/vm/drop_caches
echo 3 > /proc/sys/vm/drop_caches
```
This command is may harm to your process on running. Be careful to use. 

ORAReplication.md: https://cosol.jp/techdb/2020/05/oracle-replication-methods-support-status/)

* [Data Guard replication setting](https://udonsoba.hatenablog.com/entry/2016/06/28/172736)

* [4種類のRMAN DUPLICATEでそれぞれ実際にデータベースをコピーする](https://qiita.com/tlokweng/items/a041394e1011434eca06)
* [Duplicate from Active database](https://qiita.com/plusultra/items/51f661836828b3765d4b)

* [DataGuard構築後に使うSQLコマンドまとめ（逆引き）](https://www.ashisuto.co.jp/db_blog/article/20160831_dataguard_sql.html)

* [Dataguard status](https://dbtut.com/index.php/2020/01/30/how-to-check-data-guard-status/)
  ```sql
  -- from slave database
  https://dbtut.com/index.php/2020/01/30/how-to-check-data-guard-status/
  ```

* [Dataguard sql reference](https://www.ashisuto.co.jp/db_blog/article/20160831_dataguard_sql.html)
  ```sql
  -- check master setting
  SELECT DEST_NAME,RECOVERY_MODE FROM V$ARCHIVE_DEST_STATUS WHERE TYPE = 'PHYSICAL';
  -- check slave setting
  SELECT PROCESS,STATUS FROM V$MANAGED_STANDBY WHERE PROCESS LIKE 'MRP%';
  ```

ps-azure.md: https://www.geeksforgeeks.org/microsoft-azure-retrieve-azure-virtual-machine-admin-user-name/)
```ps1
Get-AZVM `
-Name 
taskpermission.md: https://www.intellilink.co.jp/-/media/ndil/ndil-jp/column/ms/2022/063000/package.zip)

**設定から実行までの流れ**

今回は以下のステップで進めていきましょう。

![image](https://user-images.githubusercontent.com/49302727/186832371-13f6194f-0c59-48f1-b673-572fb21890b4.png)

**実行対象と配置先を決める**

ここでいう実行対象は、スクリプトや実行ファイルなどです。
実行対象は、実行を依頼したユーザーとは別のユーザーのコンテキストで実行されるため、入力待ちが起こらないようする必要があります。
”配置先や実行対象は、管理者のみ参照・実行権限のあるようにしましょう。”さもないと、一般ユーザーが書き換えや差し替えをするだけで任意のコマンドやプログラムを実行できてしまいます。

**イベントとタスクのパラメータを決める**

**トリガーとなるイベントに必要なパラメータ**

イベントログの作成にNew-EventLog、出力のためにWrite-Eventlog コマンドレットを使用します。
タスクのイベントトリガーには「ログ」「ソース」「イベントID」が必要です。重複すると意図しないタイミングで発動してしまうので注意して設計しましょう。
今回使用するパラメータは以下の通りです。

![2022-08-26 (3)](https://user-images.githubusercontent.com/49302727/186834974-8994d4de-99fa-4288-bd17-370307c2bfde.png)


イベントは3種類用意しています。トリガーに一つ、結果に二つ使用しています。
イベントトリガーは実行が保証されません。正否がユーザーにわかるように通知する仕組みを入れるとよいでしょう。

**タスクスケジューラ**

タスクスケジューラで設定する項目は以下の通りです。

![2022-08-26 (4)](https://user-images.githubusercontent.com/49302727/186835208-57776156-5b1b-4660-844e-acbe452b2a03.png)


**イベントソースを作成する**

「管理者として実行」で起動してイベントソースを作成します。
作成には New-EventLog、削除はRemove-EventLogコマンドレットを使用します。

CreateEventSource.ps1

![2022-08-26 (5)](https://user-images.githubusercontent.com/49302727/186835423-f3b08260-9283-43ed-ac88-67445e7d48ff.png)

**実行対象を配置する**

決めた配置先にスクリプトを配置します。本番環境であれば、アクセス権の設定と確認も忘れずに。
今回はこちらのサンプルを用意しました。管理者権限が必要なセキュリティログを取得し、C:\Temp\SecurityLog.csv に出力します。サンプルなのでスクリプトも同じC:¥Temp に配置しています。
なおPowerShellのコンソールから直接このサンプルを実行する場合、[System.Environment]::Exit()の部分でPowerShellが終了してしまうので、試しに実行したい場合はコメントアウトしたり Return で置き換えてください。

C:\Temp\OutputSecurityLogs.ps1
（スクロール画像）

![image](https://user-images.githubusercontent.com/49302727/186836217-1bc3b107-222b-4d78-aea9-7d02d38f29ac.png)


**タスクを作成する**

複数台に展開するのであれば、タスクスケジューラのGUIで作成後にエクスポートします。今回はこの方法についても軽く触れます。
まずはGUIでの設定から。

**GUIでタスク作成**

全般タブの「タスクの実行時に使うユーザーアカウント」は SYSTEM とするのが一番単純なので、今回はこれを採用しています。

![image](https://user-images.githubusercontent.com/49302727/186836266-528d6963-86c8-4ffa-a9de-d072a7017f19.png)

もし特定のユーザーを指定する場合はパスワードの記録が必要となります。一方、エクスポートしたXMLにはパスワードは含まれません。インポートやそれを確定するときに必要になります。
「トリガー」には、ユーザーに発行させるイベントの情報を設定します。

![image](https://user-images.githubusercontent.com/49302727/186836321-cb101572-f894-48c0-816b-c782d71af598.png)


「操作」は実行対象を指定します。今回はPowerShell.exeとスクリプトファイルです。引数の方に実行対象となるスクリプトを指定します。

![image](https://user-images.githubusercontent.com/49302727/186836355-59b591fb-5c3d-4c13-975b-a86e6b7c5372.png)

タスクの「条件」タブですが、特に重たい処理をするのでなければ「電源」の項目のチェックを外しておくとよいでしょう。
在宅だとケーブルが抜けていたり、本体に差しているType-Cケーブルが正規の電源につながっていないために電流が足りなかったりといった状態はよくあります。

![image](https://user-images.githubusercontent.com/49302727/186836415-76d3fd65-1241-4ef1-b4e0-97e3589bb1af.png)

最後にOKを押せば確定。個別のユーザーを実行アカウントに指定していた場合はパスワードの入力が求められます。

**タスクXMLのエクスポート**

出来上がったタスクをエクスポートします。一台だけで使用するならこの手順は不要です。

![image](https://user-images.githubusercontent.com/49302727/186836443-7d333a2b-cd2e-4037-8188-19fa021c6cab.png)

**XMLの編集**

その後、必要に応じて保存されたXMLを編集します。
作成者をユーザー名にしたくないなら「Author」を修正。ユーザーを個別で指定した場合SIDが使用されますが、ローカルアカウントの場合これが端末ごとに不一致になるので「UserId」をユーザー名に修正したりします。保存の際にUTF-16とするのを忘れずに。今回はビルトインアカウント「SYSTEM」を使うのでSIDのままでもよいでしょう。

![image](https://user-images.githubusercontent.com/49302727/186836493-24bb7d30-9d56-471c-a05f-fbf51ba74ce6.png)

**タスクXMLのインポート**

タスクスケジューラのGUIを使用してXMLをインポートする場合は右ペインの「タスクのインポート」でインポートします。「タスクXMLに、書式設定が正しくない値または範囲外の値が含まれています。」というエラーが出る場合は「ユーザーまたはグループの変更」で同じユーザーアカウントを指定します。今回はOutputSecurityLogs.xmlを指定します。

![image](https://user-images.githubusercontent.com/49302727/186836526-89e683bc-3c98-4955-837f-a41dd4a7781a.png)

PowerShellであれば以下のように登録します。今回のようにSYSTEMアカウントなどパスワード不要な場合、UserとPasswordの指定は不要です。フォルダ配下なら TaskPath パラメータを追加してください。

RegisterTask.ps1

![2022-08-26 (7)](https://user-images.githubusercontent.com/49302727/186836711-c32ea883-012a-484a-94d5-beafbc68e166.png)

**ユーザーから実行する**

**イベントログに書き込む**

標準ユーザーからイベントログを書き出します。PowerShellを開いて以下のように発行します。

![2022-08-26 (8)](https://user-images.githubusercontent.com/49302727/186836967-7611d3db-e24b-4ac7-9dd2-cbd29342712d.png)

その後イベントログが出ているか確認しましょう。ログはGet-EventLogまたはGet-WinEventで取得できます。

![2022-08-26 (9)](https://user-images.githubusercontent.com/49302727/186837149-4c16dc19-9e99-4285-acac-fc4e48426010.png)

Get-EventLog と Get-WinEvent はオプションや扱えるイベントログの種類などが違います。evtxファイルとなっているログを扱えるかどうかや検索条件などの違いもあるので、適したものを選択してください。

さて。うまくいけば、ID(Get-WinEventの場合は InstanceId)が1001のログが見つかります。メッセージに書かれたCSVを開けば、システムアカウントで実行された結果の書かれたCSVが確認できるはずです。

![image](https://user-images.githubusercontent.com/49302727/186837195-1a0c5a7f-94aa-4082-8cd3-e57d69b47ee3.png)

ところでエンドユーザーにPowerShellを操作してもらうのは大変なので、ダブルクリックで動くバッチをTIPSとサンプルとして作成しました。サンプルの GetSecurityLogs.bat を実行すると、イベントログを発行してタスクの完了を待ち、結果を表示します。

**終わりに**

タスクスケジューラを使用して、標準アカウントから管理者の処理を実行する方法を紹介しました。
シンクライアント端末のように、ユーザーは管理者権限を持たせないという設計はよくあるのですが、実際運用してみると「この機能のためだけに管理者権限が欲しい」「UACの画面が邪魔」とったことがあります。
そんな時、管理者権限を一律付与したりUACを無効にする前に、こんな手法も検討してみてはいかがでしょうか。
昨今は標準ユーザーではなく、管理者権限を付与した状態でサードパーティーで監視するというケースが多々あることかと思いますが、今回紹介する方法はスタンドアロンかつWindows標準の機能で実現できます。
ちなみに私は、WORKGROUP環境のシンクライアント端末のトラブルシュートを、エンドユーザーで実行する仕組みに使ったりしました。
参考になれば幸いです。

**TIPSなど**

解説のテンポが悪くなりそうなTIPSなどをまとめました。

**PowerShellを用いたタスクのエクスポート**

もしたくさんのタスクを作ったのなら、スクリプトでまとめてエクスポートした方が楽でしょう。Get-ScheduledTask と Export-ScheduledTask コマンドを使用してXMLのテキストを取得し、それをUTF-16で保存します。
以下はタスク名に「Update」を含むタスクをXMLで保存する例です。
（スクロール画像）

**バッチファイルにPowerShellを組み込んだサンプル**

PowerShellだとダブルクリックで開くといったことはできず、ExecutionPolicyの設定などちょっと煩雑。そこで、PowerShellのコードをバッチファイルに埋め込んでしまおう…そんなサンプルです。サンプルコードの GetSecurityLogs.bat を実行するとイベントログを発行してタスクの完了を待ち、結果を表示します。
バッチファイルにPowerShellのコードを書き込むテクニックについては様々な人が研究しているようです。皆さんそれぞれ特徴があるので、見ていて興味深いものがあります。
バッチファイルは、エンコードをDefault(日本語版環境ならSJIS)にする必要があるのでその点は要注意です。

GetSecurityLogs.bat
（スクロール画像）

※文章中の商品名、会社名、団体名は、各社の商標または登録商標です。

sevengods.md: https://ja.wikipedia.org/wiki/%E4%B8%83%E7%A6%8F%E7%A5%9E))

## 七福神巡り

- [七福神巡り::結・MUSUBI](https://teaser.musubi.green/useregi.html)
  - [大黒天（一攫千金（金運））](https://teaser.musubi.green/kami01.html)
  - [恵比寿天（商売繁盛）](https://teaser.musubi.green/kami02.html)
  - [弁財天（恋愛・良縁祈願）](https://teaser.musubi.green/kami03.html)
  - [毘沙門天（勝負・必勝祈願）](https://teaser.musubi.green/kami04.html)
  - [寿老人（無病息災）](https://teaser.musubi.green/kami05.html)
  - [福禄寿（立身出世）](https://teaser.musubi.green/kami06.html)
  - [布袋尊（徳高望重）](https://teaser.musubi.green/kami07.html)




shukyo.md: https://www.bunka.go.jp/tokei_hakusho_shuppan/tokeichosa/shumu_kanrentokei/index.html
    - PDF : https://www.bunka.go.jp/tokei_hakusho_shuppan/tokeichosa/shumu_kanrentokei/pdf/h26_chosa.pdf

snn.md: https://brainchip.com/)

2. **Intel - Loihi**  
   - **Intel**이 개발한 **Loihi**는 SNN을 적용한 뉴로모픽 칩입니다.  
   - 인간의 뇌처럼 작동하도록 설계되어 **적은 전력으로 효율적인 학습**이 가능합니다.  
   - 산업용 로봇, 자율주행, 패턴 인식 등의 분야에서 연구되고 있습니다.  
   - [Loihi 2 공식 블로그](https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html)

3. **SynSense - Speck**  
   - 스위스 기반 AI 스타트업인 **SynSense**는 SNN 기반 칩인 **Speck**을 개발했습니다.  
   - 초저전력 환경에서 동작할 수 있도록 설계되었으며, 특히 **실시간 음성 및 영상 인식**을 목표로 합니다.  
   - IoT, 스마트 디바이스, 웨어러블 기기 등에 적용될 수 있습니다.  
   - [공식 웹사이트](https://www.synsense-neuromorphic.com/)

4. **기타 연구 및 프로젝트**
   - **프랑스 CNRS 연구소의 SNN 기반 로봇 제어**  
     - SNN을 활용한 자율주행 드론 및 로봇 연구 진행  
   - **IBM TrueNorth** (IBM의 뉴로모픽 칩)  
     - 2010년대 연구되었으나, 현재는 Intel Loihi에 비해 연구가 활발하지 않음  
   - **네이처 및 MIT 연구팀의 SNN 기반 패턴 인식 연구**  
     - 뇌파 분석 및 신경과학 연구에 활용  

---

### **SNN을 활용한 AI 서비스의 장점**
- **초저전력, 저비용**: DNN 대비 연산량이 적고, IoT/엣지 디바이스에서 효과적  
- **실시간 학습 가능**: 환경 변화에 따라 빠르게 적응하는 시스템 구현 가능  
- **생물학적 신경망과 유사**: 인간 두뇌의 뉴런 발화(Spike)를 모방하여 효율적인 정보 처리  

---

### **SNN 기반 AI의 한계**
- **학습 방식이 아직 비효율적**: DNN보다 학습 데이터 활용 및 최적화가 어렵다.  
- **소프트웨어 및 프레임워크 부족**: TensorFlow/PyTorch와 같은 대중적인 개발 환경이 많지 않음.  
- **대규모 AI 모델 적용 어려움**: 현재 대형 AI 모델(LLM 등)에는 SNN이 적용되기 어려운 구조.

---

### **SNN이 유망한 분야**
1. **엣지 AI (Edge AI)**: IoT, 스마트 센서, 스마트 워치 등  
2. **의료/헬스케어**: EEG(뇌파), 신경 인터페이스, 생체신호 분석  
3. **자율주행 및 로보틱스**: 저전력 환경에서 실시간 의사결정 가능  

---

### **결론**
SNN을 기반으로 한 AI 서비스는 현재 **IoT, 엣지 디바이스, 헬스케어, 뉴로모픽 컴퓨팅 분야**에서 연구 및 적용되고 있습니다. 하지만, 기존 DNN 기반 LLM처럼 **대규모 AI 서비스에는 아직 적용이 어려운 단계**입니다. 향후 저전력 AI 칩과 뉴로모픽 컴퓨팅 기술이 발전하면 SNN 기반 AI 서비스도 점점 확대될 가능성이 있습니다.

ssl.md: https://certbot.eff.org/

install certbot
```sh
dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm  
dnf config-manager --set-enabled PowerTools
# -- no match

# select by environment
# for apache
dnf install certbot python3-certbot-apache
# for nginx
dnf install certbot python3-certbot-nginx
# for windows
winget install certbot
```

SSL발행
```sh
certbot certonly --manual -d *.littleworld.net --key-type rsa --agree-tos --manual-public-ip-logging-ok
```
명령을 실행하면 email 요청함. 이메일 입력하면 . 
```
ould you be willing, once your first certificate is successfully issued, to
share your email address with the Electronic Frontier Foundation, a founding
partner of the Let's Encrypt project and the non-profit organization that
develops Certbot? We'd like to send you email about our work encrypting the web,
EFF news, campaigns, and ways to support digital freedom.
```
라고 표시되는데 Y를 눌러 이메일 등록. 

```
Please deploy a DNS TXT record under the name:

_acme-challenge.littleworld.net.

with the following value:

cJVlZDstMqheupXCSRfKrj0FCmQ8g7UKOZsN2uLUGPs

Before continuing, verify the TXT record has been deployed. Depending on the DNS
provider, this may take some time, from a few seconds to multiple minutes. You can
check if it has finished deploying with aid of online tools, such as the Google
Admin Toolbox: https://toolbox.googleapps.com/apps/dig/#TXT/_acme-challenge.littleworld.net.
Look for one or more bolded line(s) below the line ';ANSWER'. It should show the
value(s) you've just added.
```
라고 DNS레코드 등록하여 오너 인증을 해야 함. 

DNS에서 Txt레코드를 등록
DNS인증이 완료되면 
```
uccessfully received certificate.
Certificate is saved at: /etc/letsencrypt/live/littleworld.net/fullchain.pem
Key is saved at:         /etc/letsencrypt/live/littleworld.net/privkey.pem
This certificate expires on 2023-09-25.
These files will be updated when the certificate renews.

NEXT STEPS:
- This certificate will not be renewed automatically. Autorenewal of --manual certificates requires the use of an authentication hook script (--manual-auth-hook) but one was not provided. To renew this certificate, repeat this same certbot command before the certificate's expiry date.

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
If you like Certbot, please consider supporting our work by:
 * Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate
 * Donating to EFF:                    https://eff.org/donate-le
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
```
라고 표시되면서 종료되면 완료. 

`/etc/letsencrypt/archive/`에 파일들이 정상적으로 들어있는지 확인후 문제 없으면 필요한 파일로 변형하여 저장. 
pem밖에 없으므로 pfx나 다른 파일로는 openssl등의 툴로 변환을 해야 함.

Azure Application Gateway등에 넣을 pfx 포맷으로 변경(openssl 설치 필요)
```sh
openssl pkcs12 -inkey privkey1.pem -in cert1.pem -export -out fullchain.pfx
```

https://github.com/LowyShin/KnowledgeBase/blob/master/dic/o/openssl.md

### 참고

- windows의 경우 certbot 명령을 쉽게 해주는 batch를 만들 수 있습니다. 보통 C:\Program Files\Certbot\bin 에 실행프로그램이 있으므로 환경변수의 PATH에 추가를 해야 합니다.
- certexec.bat
```bat
@ECHO off
REM certbot wrapper
REM sslcert musubi.green [test]
REM  test를 지정하면 --dry-run (시뮬레이션)을 붙여 실행합니다.
SETLOCAL
if 
stable_diffusion.md: https://upload.wikimedia.org/wikipedia/commons/f/f6/Stable_Diffusion_architecture.png)
- https://ja.wikipedia.org/wiki/Stable_Diffusion

기본 개념은 화상을 픽셀공간에서 저차원잠재공간으로 압축하여 화상에서의 기본 의미를 찾는다. 
압축된 잠재표현에 순방향 확산 처리(forward diffusion process)에서 가우시안 노이즈가 연속적으로 부여된다.  
ResNet으로 구성된 U-Net블록은 잠재표현을 얻기 위해 순방향 확산 과정의 출력을 다시 노이즈 제거를 진행한다. 
이걸 역방향 확산 처리(reverse diffusion process)라고 한다.
마지막으로 VAE디코더가 잠재 표현을 픽셀 공간에 역변환하여 최종 화상을 생성한다. 

노이즈 제거 과정은 문자열, 화상, 그 밖의 요소에 의해 유연하게 조건을 지정할 수 있다. 
인코드 된 조건 부여를 위한 데이터는 cross-attention구축에 의해 denosing U-Net에 부여된다. 

## 활용

- [stable diffusion을 이용한 AI 그림 생성 모듈을 쉽게 만든 WEBUI의 설치 방법](https://arca.live/b/aiart/68917133)
  - [AI가 실사와 애니풍을 정도를 조정해서 그려주는 사례](https://www.clien.net/service/board/park/17932600)
    <BR> Real 100% -> 75% -> 50% -> 25%
    <BR>
    <img src=
stable_diffusion.md: https://prompts.co.kr/bbs/board.php?bo_table=gallery&wr_id=125)
- [AI Tool Reveals How Celebrities’ Faces Have Been Photoshopped](https://petapixel.com/2023/02/28/ai-tool-reveals-how-celebrities-faces-have-been-photoshopped/)
  - AI가 사진에서 어느 부분을 리터칭을 했는지 판별해 주는 툴

## 이슈

Stable Diffusion에서 생성된 화상의 원본중에 Pinterest가 9.5%, 기타 WordPress, Blogspot, Flickr, DevianArt, Wikipedia commons 등의 
웹사이트에서 약 1200만매의 화상을 가져와 샘플링 했기 때문에 이에 대한 저작권 이슈 등이 존재 한다. 


## 참고

- Wikipedia(ja) : https://ja.wikipedia.org/wiki/Stable_Diffusion

### 출처
 - https://github.com/LowyShin/KnowledgeBase/blob/master/dic/s/stable_diffusion.md

synergy.md: https://symless.com/synergy


trendmicro.md: https://www.trendmicro.com/ja_jp/buy/license.html)

wget.md: http://www.hatena.ne.jp
```

名前を付けて保存
```sh
# (-O <path><filename>)で名前を指定してダウンロード
wget http://www.hatena.ne.jp -O ./DL/hatena-top.html
```

SSLの付いたサイトへアクセスするには
```sh
# httpsなサイトから、sslに対応していないwgetを使うとエラーになるので--no-check-certificateで無視して落とせる
wget --no-check-certificate <URL>

# ~/.wgetrcにルート証明書などを追記してやれば、wgetをsslに対応させることもできる
# wget -q http://curl.haxx.se/ca/cacert.pem -O ~/.cacert.pem
# echo ca-certificate = ~/.cacert.pem >> ~/.wgetrc 
# ユーザーごとではなく、全体に対応させる場合は/etc/wgetrcに追記する
```

BASIC認証で制限の掛かったサーバーからwgetする方法
```sh
# BASIC認証は最近見かけなくなりましたが、こんな感じで
wget --http-user={username} --http-passwd={password} {url} 
```

OAuth認証のかかったサーバはcookiesで対応する
```sh
wget --save-cookies cookies.txt --post-data 'user=foo&password=bar' http://server.com/auth.php
wget --load-cookies cookies.txt -p http://server.com/interesting/article.php
```

ユーザエージェントをつけてアクセスする場合
```sh
# 携帯サイトからデータを引っ張るときとか、UAを偽装しないといけないときなど
wget --user-agent=
wget.md: http://server/app/myservice.asmx -O response.xml

# jsonをポストして、jsonを受ける場合
wget --post-file=soaprequest.json --header=
wget.md: http://server/app/myservice.asmx -O response.json
wgetでRestful APIへアクセスする
wget -dvO- --post-file request.xml http://example.net/service
```

クッキーを無効にして、ヘッダーをつけてJDKを落とす
```sh
wget --no-check-certificate --no-cookies --header 
wget.md: https://secure.nicovideo.jp/secure/login?site=niconico
wget.md: http://seiga.nicovideo.jp/api/theme/data?theme%5Fid=87011
wget.md: http://www.google.co.jp/'
```

Refererの設定
```sh
wget 
wget.md: http://example.com/example.html
wget.md: http://axfc.uploader.local/file=テストファイル.zip
wget.md: https://qiita.com/hirohiro77/items/b774908436ec032df719)

extdata.md: https://giipteststr.blob.core.windows.net/numbers/20230821/0.txt'
--	DATA_SOURCE = 'SqlOnDemandDemo',
	, SINGLE_BLOB
--	format = 'CSV', 
--	FIELDTERMINATOR = ',',
--	ROWTERMINATOR = '\n',
--	firstrow = 1
	) 
	as rows
--
```
여러가지 옵션들을 주석처리를 했다가 풀었다가 해봤는데 결국 `Operating system error code 997(Overlapped I/O operation is in progress.).` 에러가 나서 포기. 
파일 위치를 로컬 피씨에서 하면 997 에러가 나고, Storage Account에 올려서 공유를 다 풀어서 해도 `Operating system error code (null).`
발생.. 

전부 포기하고 
Storage Account에 올린 파일을 External Data Source로 세팅. 

데이터가 보안이 필요한 경우는 Credential설정을 해야 하는데, 이번 데이터는 크롤한 데이터이기 때문에 이미 인터넷에 있어서 보안설정 무시함. 

```sql
-- 외부 데이터 소스로 한 번만 설정. 아래 CREDENTIAL이 필요 없어서 주석처리함.
CREATE EXTERNAL DATA SOURCE giipstrtest01
WITH ( TYPE = BLOB_STORAGE,
          LOCATION = 'https://giipstrtest01.blob.core.windows.net'
--          , CREDENTIAL= sampleblobcred1
);

-- 생성확인
select * from sys.external_data_sources

-- 데이터를 내가 원하는 테이블에 집어 넣는 SQL
-- Azure의 날짜 표기는 getdate()를 하면 UTC에서 변경 불가능하여 JST로 가져오는 함수를 따로 만듬. dbo.fgetJST()
insert into tRawData(rdRegdt, rdData)
select dbo.fgetJST(), convert(varchar(max), BulkColumn)
FROM OPENROWSET( 
BULK 'numbers/20230821/0.txt',
DATA_SOURCE = 'giipstrtest01', SINGLE_BLOB) AS rdData

```

rds-for-sqlserver.md: https://docs.aws.amazon.com/ja_jp/AmazonRDS/latest/UserGuide/SQLServer.ReadReplicas.html

### SQL Server でのリードレプリカの制限

Amazon RDS の SQL Server リードレプリカには、次の制限が適用されます。

- リードレプリカは、SQL Server Enterprise Edition (EE) エンジンでのみ使用することができます。

- リードレプリカは、SQL Server バージョン 2016 – 2022 で使用できます。

- 1 つのソース DB インスタンスから最大 15 つのリードレプリカを作成できます。ソース DB インスタンスのリードレプリカが 5 つを超えると、レプリケーションで遅延が発生する場合があります。

- リードレプリカは、4 つ以上の vCPU を持つ DB インスタンスクラスで実行されている DB インスタンスでのみ使用できます。

- リードレプリカは、インスタンスクラスタイプと可用性モードに応じて最大 100 のデータベースをサポートします。データベースをリードレプリカに自動的にレプリケートするには、ソース DB インスタンスでデータベースを作成する必要があります。レプリケートするデータベースを個別に選択することはできません。詳細については、「Microsoft SQL Server DB インスタンスの制限」を参照してください。

- リードレプリカからデータベースを削除することはできません。データベースを削除するには、rds_drop_database ストアドプロシージャを使用してソース DB インスタンスから削除します。詳細については、「Amazon RDS for Microsoft SQL Server データベースの削除」を参照してください。

- ソース DB インスタンスが透過的なデータ暗号化 (TDE) を使用してデータを暗号化すると、リードレプリカも TDE を自動的に設定します。

- ソース DB インスタンスが KMS キーを使用してデータを暗号化すると、同じリージョンのリードレプリカは同じ KMS キーを使用します。クロスリージョンリードレプリカの場合、リードレプリカの作成時にリードレプリカのリージョンから KMS キーを指定する必要があります。リードレプリカの KMS キーを変更することはできません。

- リードレプリカは、作成元のアベイラビリティーゾーンに関係なく、ソース DB インスタンスと同じタイムゾーンと照合順序を持ちます。

- Amazon RDS for SQL Server では、次の機能はサポートされていません。

  - リードレプリカのバックアップ保持

  - リードレプリカからのポイントインタイムリカバリ

  - リードレプリカの手動スナップショット

  - マルチ AZ リードレプリカ

  - リードレプリカのリードレプリカの作成

  - リードレプリカへのユーザーログインの同期

- Amazon RDS for SQL Server は、ソース DB インスタンスとそのリードレプリカの間の高いレプリカラグを軽減するために介入することはありません。ソース DB インスタンスとそのリードレプリカのサイズが、コンピューティング能力とストレージの観点から、運用負荷に合わせて適切に設定されていることを確認してください。

- AWS GovCloud (米国東部) と AWS GovCloud (米国西部) リージョンの間ではレプリケーションできますが、AWS GovCloud (US) Regions との間ではレプリケーションできません。

timezoneinfo.md: https://learn.microsoft.com/en-us/sql/relational-databases/system-catalog-views/sys-time-zone-info-transact-sql?view=sql-server-ver16)
  - Azure는 DB에 UTC를 기본으로 저장. Country code등을 바꾸는 기능이 없기 때문에 다음과 같이 표현을 해야 한다. 
  ```sql
  select getdate() at time zone 'Tokyo Standard Time'
  ```
  - 이 경우 zone에 해당하는 스트링이 sql database의 시스템 테이블에 있는데 그 내용을 확인하려면 time_zone_info 테이블을 확인하면 된다. 
    (jp, kr등의 컨트리 코드와 연결이 되어 있지 않은데다가 하나의 지역코드가 광활 하면 여러 타임존을 넘나들어 DB화 하기가 무척 힘들다)
  ```sql
  select * from sys.time_zone_info
  ```

twitter.md: https://publish.twitter.com/
  - 트위터의 URL을 넣으면 자동으로 해당 내용을 publish하는 태그가 생성됨
    ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/f265f25d-82c1-49e4-86d4-75f4a1da44ef)

- 퍼블리싱할 위치를 찾아서 URL복사
  ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/e6c11215-4588-4daf-96ef-de24a56b5805)
  - 특정 유저를 누르면 유저의 Home URL이 표시됨. 그걸 베이스로 태그 생성
- publisher 에 붙여넣고 생성
  ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/59885e79-55b5-47e1-b96f-d0f35f4061ce)
  - Embedded Timeline 이 보통 붙여넣는 타임라인 전체임
- 코드를 복사해서 자신의 홈페이지에 붙여 넣음
  ![image](https://github.com/LowyShin/KnowledgeBase/assets/20239203/13420538-c462-4a27-8fe3-14a6900e66b5)


tidb-backup-table.md: https://docs.pingcap.com/tidb/stable/dumpling-overview)から、Dumplingのインストール方法を確認できます。

#### 2. テーブルバックアップの実行
Dumplingコマンドを使って、指定されたテーブルをバックアップします。以下は具体的なコマンド例です。

```bash
dumpling \
  --host 127.0.0.1 \
  --port 4000 \
  --user root \
  --password password \
  --filetype sql \
  --tables-list database_name.table_name \
  --output ./backup
```

このコマンドでは以下のオプションが使用されています。

- `--host`: TiDBクラスタのホスト
- `--port`: TiDBのポート番号（デフォルトは4000）
- `--user`: 接続に使用するユーザー名
- `--password`: 接続に使用するパスワード
- `--filetype`: エクスポート形式（`sql`、`csv`などが選択可能）
- `--tables-list`: バックアップするテーブルを指定（複数のテーブルも指定可能）
- `--output`: エクスポートしたデータの保存先ディレクトリ

#### 3. エクスポートされたデータの確認
指定したディレクトリにエクスポートされたSQLファイルが保存されます。このファイルを確認し、必要に応じて他の環境にインポートする準備をします。

### 追加のオプション
- `--threads`: Dumplingがデータをエクスポートする際に使用するスレッド数を指定します。デフォルトは4です。
- `--chunk-filesize`: ファイルのチャンクサイズを指定します（デフォルトは64MiB）。

Dumplingは大規模なデータを高速でエクスポートするのに適しており、分散環境にも対応しています。もし単一テーブルだけでなくデータベース全体のバックアップや、リカバリに関する情報が必要であれば、PingCAPの[公式ドキュメント](https://docs.pingcap.com/tidb/stable/dumpling-overview)で詳細な説明がされています。

バックアップの対象やリカバリ方法についてさらに詳しく知りたい場合は、質問を教えてください。

LoadTest.md: https://dbstudy.info/jdbcrunner/docs_ja/tutorial.html

immersed.md: https://immersed.com/

## Requirement

* Oculus Quest 2 
* Windows / Mac / Linux

## Intro

PCを仮想空間に映すサービス。コンセントは仮想オフィスになっており、一緒に会議したり共同作業することができます。

何よりすごいのは、コロナ過になってシェアオフィスなどに移動して作業したりするケースが多いですが、その時大きいモニターを持っていけないのが当然だと思います。
その時Oculusだけあれば自分の好きな大きさのスクリーンを5つ（無料バージョンは2つ）まで立ち上げることができます。

そして色んな便利機能がありこれからも発展し続けると思います。

まずMETABUSを経験したい方はまずImmersedを推奨します！

## 初期設定

* OculusのAppストアからImmersed Appをインストールします。
* Immersedを起動するとそれに従いPCにImmersed Agentをインストールします。
* Tutorialが英語でしかないですが、基本操作には大事なのでやってみることをお勧めします。
  * Tutorial中にクイックメニューを出すのが個人的に一番難しかったですが、
  コントローラーをつかんだ状態で自分の手首のバッテリーが表示されている円マークをじっくり見ると中の緑の円状が大きくなりメニューが出てきます。
 
## Tips!

### キーボード

仮想キーボードはあまり役に立ちません。しかし仮想キーボードを物理キーボードと合わせる方法があります！

1. まず仮想キーボードを出します。
2. キーボードの下にCalibrateというボタンが出ます。
  * ジェスチャー機能がアクティブ中ではないとCalibrateボタンが表示されません。自分の手と合わせて調整するからです。
3. ボタンをクリックすると物理キーボードのPボタンを長く押すとP文字の周りに円表示が出ます。
4. 次はQボタンを同じくじっくり押します。
5. 次はBボタンをじっくり押します。
6. すると、自動的に仮想キーボードが物理キーボードと合体します！
7. では手の動きを見ながらキーボードをタイピングできます。

もう一つはPassthrough Keyboardという機能です。

1. コントローラーのoculusボタンまたはQuickメニューからメインメニューを開きます。
2. メインメニューの下にKeyboardがあるんですがカーソルをかざすとPassthrough Keyboardというのがあります。
3. クリックしてキーボードのところを合わせるとあそこだけがOculusカメラから見える窓が開きます。
4. それで完全に物理キーボードと自分の手で見ることができます。

ちなみに、私は毎回仮想キーボードを合わせるのが面倒でPassthrough Keyboardを使ってしまいました。

### ジェスチャー

Immersedでジェスチャーは大事です。しかし間違ったら勝手にクリックされたりするのでDefaultのMonitor InputをOFFにして
慣れたらMonitor InputをONにして手とキーボードだけで作業ができればもっと効率高い作業環境が得られると思います。

ジェスチャーの設定はOculus設定のところにジェスチャーをONする必要があります。





windows.md: https://mugendennou.net/win-server/bginfo/)

- [EvetCreate.exe(official)](https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/eventcreate)

### C드라이브 압박시 대처방법

- 크롬 템프 디렉토리의 이동
  - 크롬을 종료(태스크 매니저에 크롬 관련 뜬거 모두 종료)

1. Shut down Chrome. Then open Task Manager and check the processes and make sure the Chrome process is not running. Just closing Chrome doesn't always shut down the Chrome process, and if it's running, it will lock certain files that you need to move in the next step.
 
2. Create a directory at some suitable location where you want the cache to go, for example D:\Chrome Cache and Profile.
 
3. Navigate to where Chrome is installed, and move the entire 
career.md: https://www.pasonacareer.jp/
- RECRUIT AGENT 転職エージェント
  - https://www.r-agent.com/
- Indeed
  - https://jp.indeed.com
- エンワールド・ジャパン - 年収800-2000万円ハイクラス求人
  - https://www.enworld.com
- doda
  - https://www.doda.jp
- Remogu - フリーランス・正社員
  - https://remogu.jp/
- https://www.green-japan.com/
- https://bizreach.biz/
- https://levtech.jp/
- https://lapras.com/
- https://en-gage.net/

- update
  - https://github.com/LowyShin/KnowledgeBase/issues/20
  - 

chara-goods.md: https://hotmobily.jp/
- 有限会社ケーアンドエー（K&A CO.,LTD.）
  - https://www.goods-express.info/scene/animation/


creator.md: https://github.com/LowyShin/KnowledgeBase/files/13234543/cr_231031_01.pdf)

influencer.md: https://influencer-portal.com/influencer)

pg.md: https://www.epsilon.jp/campaigns/fast-plan/#price)

seo-kr.md: https://www.hedleyonline.com/ko/blog/%ec%8a%a4%ed%82%a4%eb%a7%88/
- SEO(검색엔진최적화)가이드북 총정리 2023
  - https://www.hedleyonline.com/ko/blog/seo-guide/

_Sidebar.md: https://translate.googleusercontent.com/translate_c?depth=1&hl=en&rurl=translate.google.com&sl=auto&sp=nmt4&tl=ja&u=https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki&usg=ALkJrhgmYJ2j5I5KtTO5ROlKUAYf8bQMcw)

## [KnowledgeBase](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki)

* [Markdown](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Markdown)

### Data(DBMS, NoSQL)

* [MachineLearning](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/MachineLearning)
* [SQL Server](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/SQL-Server)
* ORACLE
  * [Basic Management](https://talklowy-jp.blogspot.com/2020/10/oracle-management-knowledge.html)
  * [Installation](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/ORACLEInstallTips)
  * [DDL](https://talklowy-jp.blogspot.com/2020/10/oracle-ddl-lowy-knowledgebase.html)
  * [ORACLETuning](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/ORACLETuning)
  * [Merge Into/Update Join](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/MERGE)
  * [Useful SQL](https://talklowy-jp.blogspot.com/2020/10/oracle-useful-sql.html)
  * [TableSpaceManagement](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/TableSpaceManagement)
  * [datetime](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/datetime)
  * [Flashback](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Flashback)
  * [BackupRestore](https://talklowy-jp.blogspot.com/2021/02/oracle-backup-and-restore-lowy.html)
  * [Characterset(Official)](https://www.oracle.com/technetwork/jp/content/charcterset-250314-ja.pdf)
* [MySQL](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/MySQL)
  * [my.cnf](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/my.cnf)
  * [date_format](MySQLDateFormat)
  * [Replication](https://talklowykr.blogspot.com/2021/03/mysql-replication.html)
* [Mongodb](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Mongodb)
* [Apache-Drill](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Apache-Drill)
* [A5MK2-MultiDBMSTool](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/A5MK2)
* [BI](BI)
* [Referrals](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Referrals)


### Development

* [DataVisual](https://observablehq.com/@d3/gallery)
* [Python](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Python)
* [Classic ASP](https://github.com/LowyShin/KB-ClassicASP/wiki)
* [wsf](https://github.com/LowyShin/KB-ClassicASP/wiki/wsf)
* [WMI](WMI)
* [HTML](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/HTML)
  * [HTML(kr)](https://talklowykr.blogspot.com/2021/01/html-1-html.html)

### Tools

* [git](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/git)
* [GoogleSheet](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/GSheet)
* [UiPath(RPA)](https://github.com/LowyShin/lwrpa-uip-study-ja/wiki)
* [WinAutomation(official)](https://docs.winautomation.com/V9_0/en/winautomation.html)
* [Excel](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Excel)
* [VNC](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/VNC)
* [VPN](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/VPN)
* [Note Tool](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Note-Tool)
* [Blog](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Blog)

### Management

* [Shell/bash](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Shell)
* [crontab](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/crontab)
* [PowerShell](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/PowerShell)
* [Windows(DOS) batch](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/WinBatch)
* [Wscript/wsf](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Wscript)
* [Azure](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Azure)
* [File Sync](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Sync)
* [KnownPort(wikipedia)](https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers)

### OS

* [CentOS](https://github.com/LowyShin/KnowledgeBase/tree/master/wiki/CentOS)
* Android
  * [Rooting app](https://talklowy-jp.blogspot.com/2020/10/android-rooting-app.html)
  * [adb shell](https://talklowy-jp.blogspot.com/2020/10/android-rooting-app.html)

### Hardware

* [Xeon CPU](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Xeon-CPU)
* [Paloalto FW Lineup](https://www.techmatrix.co.jp/product/paloalto/spec_lineup.html)

### Business

* [Startup checkpoint(jp)](StartupChkJP)

### Hobby

* [Electronic goods](https://github.com/LowyShin/KB-KnowledgeBaseHome/wiki/Electronic-goods)

## Giip(RPA Engine)

* [giip docs](https://github.com/LowyShin/giip)
* [giip website](https://giipasp.azurewebsites.net)


